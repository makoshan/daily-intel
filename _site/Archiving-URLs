<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Inlined head (no SSI): injected by Hakyll from static/include/inlined-head.html -->
  <style id="inlined-styles-colors">
:root {
    /*  General.
     */
    --GW-body-background-color: #fff;
    --GW-body-text-color: #000;

    /*  Selection.
     */
    --GW-text-selection-background-color: #333;
    --GW-text-selection-color: #fff;

	/*	Links.
	 */
    --GW-body-link-color: #333;
    --GW-body-link-hover-color: #888;
    --GW-body-link-visited-color: #666;
    --GW-body-link-inverted-color: #eee;
    --GW-body-link-inverted-hover-color: #ccc;
    --GW-body-link-inverted-visited-color: #ddd;

    /*  Blockquotes.
     */
    --GW-blockquote-border-color-level-one: #ccc;
    --GW-blockquote-border-color-level-two: #c4c4c4;
    --GW-blockquote-border-color-level-three: #b3b3b3;
    --GW-blockquote-border-color-level-four: #a6a6a6;
    --GW-blockquote-background-color-level-one: #f8f8f8;
    --GW-blockquote-background-color-level-two: #e6e6e6;
    --GW-blockquote-background-color-level-three: #d8d8d8;

    /*  Abstracts.
     */
    --GW-abstract-border-color: #bbb;

	/*	Block context highlighting.
	 */
	--GW-block-context-span-highlight-color: #ddd;

    /*  Table of contents.
     */
    --GW-TOC-border-color: #ccc;
    --GW-TOC-background-color: #f8f8f8;
    --GW-TOC-collapse-button-text-color: #ccc;
    --GW-TOC-collapse-button-text-hover-color: #fff;
    --GW-TOC-collapse-button-color: rgba(248, 248, 248, 0.8);
    --GW-TOC-collapse-button-hover-color: #ddd;
    --GW-TOC-collapse-button-border-hover-color: #000;
    --GW-TOC-link-hover-background-color: #ececec;
    --GW-TOC-link-hover-color: #000;
    --GW-TOC-link-hover-indicator-bar-color: #ccc;
    --GW-TOC-number-color: #909090;
    --GW-TOC-number-hover-color: #313131;

    /*  Collapse blocks.
        */
	--GW-collapse-abstract-blockquote-hover-color: #eee;
	--GW-collapse-disclosure-button-color: #eee;
	--GW-collapse-disclosure-button-hover-color: #ddd;
	--GW-collapse-in-blockquote-disclosure-button-color: #ddd;
	--GW-collapse-in-blockquote-disclosure-button-hover-color: #ccc;
	--GW-collapse-disclosure-button-text-color: #bbb;
	--GW-collapse-disclosure-button-text-hover-color: #fff;
	--GW-collapse-in-blockquote-disclosure-button-text-color: #999;
	--GW-collapse-in-blockquote-disclosure-button-text-hover-color: #888;

	/*	Inline collapses.
	 */
	--GW-collapse-inline-disclosure-button-text-color: #555;
	--GW-collapse-inline-disclosure-button-text-hover-color: #999;

	/*	Aux-links collapse blocks.
	 */
	--GW-aux-links-collapse-border-color: #c4c4c4;

    /*  Headings.
     */
    --GW-H1-border-color: #888;
    --GW-H2-border-color: #888;

    /*  Comments.
     */
    --GW-comment-section-top-border-color: #999;

    /*  Lists.
     */
    --GW-bulleted-list-marker-color: #808080;

    /*  Figures.
     */
    --GW-figure-outline-color: #888;
    --GW-figure-caption-outline-color: #888;

	/*	Embeds.
	 */
	--GW-embed-border-color: #ddd;

    /*  Epigraphs.
     */
    --GW-epigraph-quotation-mark-color: #808080;

    /*  Footnotes.
     */
    --GW-footnote-border-color: #aaa;
    --GW-footnote-highlighted-border-color: #aaa;
    --GW-footnotes-section-top-rule-color: #ccc;
    --GW-footnote-backlink-border-color: #000;
    --GW-footnote-backlink-border-hover-color: #999;

    /*  Footnote references.
     */
    --GW-highlighted-link-outline-color: #999;

    /*  Sidenotes.
     */
    --GW-sidenote-highlight-box-shadow-color: #aaa;
    --GW-sidenote-border-color: #aaa;
    --GW-sidenote-scrollbar-thumb-color: #aaa;
    --GW-sidenote-scrollbar-thumb-hover-color: #999;
    --GW-sidenote-self-link-border-color: #aaa;

	/*	Annotations.
	 */
	--GW-section-highlighted-border-color: #666;

    /*  Tables.
     */
    --GW-table-border-color: #000;
    --GW-table-caption-border-color: #000;
    --GW-table-row-horizontal-border-color: #000;
    --GW-table-scrollbar-thumb-color: #aaa;
    --GW-table-scrollbar-thumb-hover-color: #999;
    --GW-table-scrollbar-border-color: #000;
    --GW-table-column-heading-hover-background-color: #e2f0f2;
    --GW-table-sorted-column-heading-background-color: #8bd0ed;
    --GW-table-sorted-column-heading-text-color: #fff;
    --GW-table-sorted-column-heading-text-shadow-color: #000;
    --GW-table-zebra-stripe-alternate-row-background-color: #f6f6f6;
    --GW-table-row-hover-outline-color: #000;

    /*  Code blocks.
     */
    --GW-code-element-border-color: #c8c8c8;
    --GW-code-element-background-color: #fafafa;
    --GW-pre-element-border-color: #c8c8c8;
    --GW-pre-element-background-color: #fafafa;
    --GW-pre-element-scrollbar-track-color: #fafafa;
    --GW-pre-element-scrollbar-thumb-color: #ccc;
    --GW-pre-element-scrollbar-thumb-hover-color: #999;
    --GW-code-block-line-highlight-background-color: #ffd;
    --GW-code-block-line-highlight-border-color: #ddd;
    --GW-code-block-line-number-color: #aaa;
    --GW-code-block-line-number-divider-color: #ccc;


    /*  Syntax highlight theme.
     */
    --GW-syntax-highlight-color-normal: #1f1c1b;
    --GW-syntax-highlight-color-attribute: #002561;
    --GW-syntax-highlight-color-data-type: inherit;
    --GW-syntax-highlight-color-variable: #666666;
    --GW-syntax-highlight-color-other: inherit;
    --GW-syntax-highlight-color-preprocessor: inherit;
    --GW-syntax-highlight-color-extension: #777;
    --GW-syntax-highlight-color-comment: #77947b;
    --GW-syntax-highlight-color-control-flow: #003900;
    --GW-syntax-highlight-color-keyword: #002561;
    --GW-syntax-highlight-color-operator: #002561;
    --GW-syntax-highlight-color-special-char: #607880;
    --GW-syntax-highlight-color-built-in: #002561;
    --GW-syntax-highlight-color-function: #002561;
    --GW-syntax-highlight-color-constant: inherit;
    --GW-syntax-highlight-color-base-n: inherit;
    --GW-syntax-highlight-color-dec-val: inherit;
    --GW-syntax-highlight-color-float: inherit;
    --GW-syntax-highlight-color-information: inherit;
    --GW-syntax-highlight-color-char: inherit;
    --GW-syntax-highlight-color-string: inherit;
    --GW-syntax-highlight-color-verbatim-string: inherit;
    --GW-syntax-highlight-color-alert: #bf0303;
    --GW-syntax-highlight-color-error: #ff0000;
    --GW-syntax-highlight-color-import: #777777;
    --GW-syntax-highlight-color-special-string: #666666;

    /*  Math.
     */
    --GW-math-block-background-color: #f6f6f6;
    --GW-math-block-background-color-flash: #fff;
    --GW-math-block-scrollbar-border-color: #ccc;
    --GW-math-block-scrollbar-thumb-color: #ccc;
    --GW-math-block-scrollbar-thumb-hover-color: #999;

    /*  Dropcaps.
     */
    --GW-dropcaps-goudy-color: #000;
    --GW-dropcaps-yinit-color: #0d0d0d;
    --GW-dropcaps-yinit-text-shadow-color: #777;
    --GW-dropcaps-de-zs-color: #1b1b1b;
    --GW-dropcaps-cheshire-color: #191919;
    --GW-dropcaps-kanzlei-color: #191919;

    /*  Admonitions.
     */
    --GW-admonition-note-left-border-color: #909090;
    --GW-admonition-note-background-color: #d8d8d8;
    --GW-admonition-tip-left-border-color: #d8d8d8;
    --GW-admonition-tip-background-color: #f0f0f0;
    --GW-admonition-warning-left-border-color: #5a5a5a;
    --GW-admonition-warning-background-color: #9a9a9a;
    --GW-admonition-warning-text-color: #fff;
    --GW-admonition-error-left-border-color: #2d2d2d;
    --GW-admonition-error-background-color: #5a5a5a;
    --GW-admonition-error-text-color: #fff;
    --GW-admonition-reversed-link-color: #ddd;
    --GW-admonition-reversed-link-color-hover: #ccc;
    --GW-admonition-reversed-link-underline-gradient-line-color: #ccc;
    --GW-admonition-reversed-link-underline-gradient-line-color-hover: #bbb;

	/*	Footer.
	 */
    --GW-bottom-ornament-line-color: #000;

	/*	Pop-frames (popups or popins).
	 */
    --GW-popframes-object-popframe-background-color: #fff;

    --GW-extracts-options-dialog-backdrop-background-color: rgba(255, 255, 255, 0.95);
    --GW-extracts-options-dialog-background-color: var(--GW-body-background-color);
    --GW-extracts-options-dialog-border-color: #aaa;
    --GW-extracts-options-dialog-box-shadow-color: #444;
    --GW-extracts-options-dialog-horizontal-rule-color: #ccc;
    --GW-extracts-options-dialog-button-background-color: var(--GW-body-background-color);
    --GW-extracts-options-dialog-button-text-color: #000;
    --GW-extracts-options-dialog-button-border-color: #000;
    --GW-extracts-options-dialog-button-hover-box-shadow-color: #000;
    --GW-extracts-options-dialog-option-button-explanation-text-color: #777;
    --GW-extracts-options-dialog-option-button-hover-text-color: #777;
    --GW-extracts-options-dialog-radio-button-border-color: #000;

    /*  Popups.
     */
    --GW-popups-popup-background-color: var(--GW-body-background-color);

    --GW-popups-popup-border-color: #ccc;
    --GW-popups-popup-box-shadow-color: #ccc;
    --GW-popups-popup-border-focused-color: #aaa;
    --GW-popups-popup-box-shadow-focused-color: #aaa;

    --GW-popups-popup-title-bar-background-color: #fff;
    --GW-popups-popup-title-bar-button-color: #bbb;
    --GW-popups-popup-title-bar-button-color-hover: #000;
    --GW-popups-popup-title-bar-button-color-disabled: #eee;
	--GW-popups-popup-title-color: #aaa;
    --GW-popups-popup-title-link-hover-color: var(--GW-body-link-hover-color);
    --GW-popups-popup-title-bar-button-focused-color: #777;
    --GW-popups-popup-title-bar-button-focused-color-hover: #000;
    --GW-popups-popup-title-bar-button-focused-color-disabled: #ddd;
    --GW-popups-popup-title-bar-submenu-box-shadow-color: #ddd;
	--GW-popups-popup-title-focused-color: #000;
    --GW-popups-popup-title-link-hover-focused-color: var(--GW-body-link-hover-color);

    --GW-popups-popup-scrollbar-thumb-color: #ddd;
    --GW-popups-popup-scrollbar-thumb-hover-color: #bbb;
    --GW-popups-popup-scrollbar-thumb-focused-color: #ccc;
    --GW-popups-popup-scrollbar-thumb-hover-focused-color: #999;

    /*  Popins.
     */
    --GW-popins-popin-background-color: var(--GW-body-background-color);

    --GW-popins-popin-border-color: #aaa;
    --GW-popins-popin-backdrop-color: rgba(0, 0, 0, 0.4);
    --GW-popins-popin-box-shadow-color: #aaa;

    --GW-popins-popin-title-bar-background-color: #fff;
    --GW-popins-popin-title-bar-button-color: #777;

    --GW-popins-popin-scrollbar-thumb-color: #ccc;
    --GW-popins-popin-scrollbar-thumb-hover-color: #999;

    --GW-popins-popin-stack-counter-text-color: #fff;
    --GW-popins-popin-stack-counter-background-color: #bbb;

    /*  Image focus.
     */
    --GW-image-focus-image-hover-drop-shadow-color: #777;

	/*	Page toolbar.
	 */
    --GW-page-toolbar-border-color: #aaa;
	--GW-page-toolbar-control-button-color: #aaa;
	--GW-page-toolbar-control-button-active-color: #000;

	/*	Page toolbar widgets.
	 */
	--GW-page-toolbar-button-icon-color: #aaa;
	--GW-page-toolbar-button-selectable-icon-color: #e4e4e4;
	--GW-page-toolbar-button-selected-icon-color: #777;
    --GW-page-toolbar-button-text-color: #666;
    --GW-page-toolbar-button-disabled-text-color: #ccc;
    --GW-page-toolbar-button-highlighted-text-color: #000;

	/*	Reader mode.
	 */
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-background-color: rgba(0, 0, 0, 0.8);
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-text-color: #fff;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-text-shadow-color: #000;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-key-icon-border-color: #bbb;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-key-icon-background-color: #444;

	/*	‚ÄúBack to top‚Äù link.
	 */
	--GW-back-to-top-link-color: #ccc;
	--GW-back-to-top-link-hover-color: #999;

	/*	Mobile floating header.
	 */
	--GW-floating-header-box-shadow-color: #ccc;
	--GW-floating-header-scroll-indicator-color: #999;

	/*	‚ÄúSkip to content‚Äù accessibility link.
	 */
	--GW-skip-to-content-text-color: #fff;
	--GW-skip-to-content-border-color: #fff;
	--GW-skip-to-content-background-color: #bf1722;

	/*	Nav header.
	 */
	--GW-nav-header-link-color: #888;
	--GW-nav-header-link-hover-color: #000;

	/*	X of the day.
	 */
	--GW-x-of-the-day-border-color: #ccc;
}
:root {
    --GW-popups-popup-title-bar-pattern: var(--GW-image-pattern-dotted-e6e6e6-on-fff-2x-gif);
    --GW-popups-popup-title-bar-pattern-focused: var(--GW-image-pattern-dotted-fff-on-e6e6e6-2x-gif);

	--GW-checkerboard-scrollbar-background-image: var(--GW-image-checkerboard-777-fff-2x-gif);
	--GW-checkerboard-scrollbar-hover-background-image: var(--GW-image-checkerboard-000-fff-2x-gif);
}

@media all and (max-width: 649px) {
	.poem,
	.editorial {
		text-shadow: 0 0 0 currentColor;
	}
}
</style>
<style id="inlined-styles-colors-dark" media="all and (prefers-color-scheme: dark)">
:root {
    /*  General.
     */
    --GW-body-background-color: #000;
    --GW-body-text-color: #fff;

    /*  Selection.
     */
    --GW-text-selection-background-color: #dcdcdc;
    --GW-text-selection-color: #000;

	/*	Links.
	 */
    --GW-body-link-color: #dcdcdc;
    --GW-body-link-hover-color: #999;
    --GW-body-link-visited-color: #b4b4b4;
    --GW-body-link-inverted-color: #333;
    --GW-body-link-inverted-hover-color: #5c5c5c;
    --GW-body-link-inverted-visited-color: #494949;

    /*  Blockquotes.
     */
    --GW-blockquote-border-color-level-one: #5c5c5c;
    --GW-blockquote-border-color-level-two: #646464;
    --GW-blockquote-border-color-level-three: #747474;
    --GW-blockquote-border-color-level-four: #7f7f7f;
    --GW-blockquote-background-color-level-one: #212121;
    --GW-blockquote-background-color-level-two: #3e3e3e;
    --GW-blockquote-background-color-level-three: #4f4f4f;

    /*  Abstracts.
     */
    --GW-abstract-border-color: #6c6c6c;

	/*	Block context highlighting.
	 */
	--GW-block-context-span-highlight-color: #494949;

    /*  Table of contents.
     */
    --GW-TOC-border-color: #5c5c5c;
    --GW-TOC-background-color: #212121;
    --GW-TOC-collapse-button-text-color: #5c5c5c;
    --GW-TOC-collapse-button-text-hover-color: #000;
    --GW-TOC-collapse-button-color: rgba(33, 33, 33, 0.8);
    --GW-TOC-collapse-button-hover-color: #494949;
    --GW-TOC-collapse-button-border-hover-color: #fff;
    --GW-TOC-link-hover-background-color: #363636;
    --GW-TOC-link-hover-color: #fff;
    --GW-TOC-link-hover-indicator-bar-color: #5c5c5c;
    --GW-TOC-number-color: #929292;
    --GW-TOC-number-hover-color: #ddd;

    /*  Collapse blocks.
        */
	--GW-collapse-abstract-blockquote-hover-color: #333;
	--GW-collapse-disclosure-button-color: #333;
	--GW-collapse-disclosure-button-hover-color: #494949;
	--GW-collapse-in-blockquote-disclosure-button-color: #494949;
	--GW-collapse-in-blockquote-disclosure-button-hover-color: #5c5c5c;
	--GW-collapse-disclosure-button-text-color: #6c6c6c;
	--GW-collapse-disclosure-button-text-hover-color: #000;
	--GW-collapse-in-blockquote-disclosure-button-text-color: #8b8b8b;
	--GW-collapse-in-blockquote-disclosure-button-text-hover-color: #999;

	/*	Inline collapses.
	 */
	--GW-collapse-inline-disclosure-button-text-color: #c1c1c1;
	--GW-collapse-inline-disclosure-button-text-hover-color: #8b8b8b;

	/*	Aux-links collapse blocks.
	 */
	--GW-aux-links-collapse-border-color: #646464;

    /*  Headings.
     */
    --GW-H1-border-color: #999;
    --GW-H2-border-color: #999;

    /*  Comments.
     */
    --GW-comment-section-top-border-color: #8b8b8b;

    /*  Lists.
     */
    --GW-bulleted-list-marker-color: #9f9f9f;

    /*  Figures.
     */
    --GW-figure-outline-color: #999;
    --GW-figure-caption-outline-color: #999;

	/*	Embeds.
	 */
	--GW-embed-border-color: #494949;

    /*  Epigraphs.
     */
    --GW-epigraph-quotation-mark-color: #9f9f9f;

    /*  Footnotes.
     */
    --GW-footnote-border-color: #7c7c7c;
    --GW-footnote-highlighted-border-color: #7c7c7c;
    --GW-footnotes-section-top-rule-color: #5c5c5c;
    --GW-footnote-backlink-border-color: #fff;
    --GW-footnote-backlink-border-hover-color: #8b8b8b;

    /*  Footnote references.
     */
    --GW-highlighted-link-outline-color: #8b8b8b;

    /*  Sidenotes.
     */
    --GW-sidenote-highlight-box-shadow-color: #7c7c7c;
    --GW-sidenote-border-color: #7c7c7c;
    --GW-sidenote-scrollbar-thumb-color: #7c7c7c;
    --GW-sidenote-scrollbar-thumb-hover-color: #8b8b8b;
    --GW-sidenote-self-link-border-color: #7c7c7c;

	/*	Annotations.
	 */
	--GW-section-highlighted-border-color: #b4b4b4;

    /*  Tables.
     */
    --GW-table-border-color: #fff;
    --GW-table-caption-border-color: #fff;
    --GW-table-row-horizontal-border-color: #fff;
    --GW-table-scrollbar-thumb-color: #7c7c7c;
    --GW-table-scrollbar-thumb-hover-color: #8b8b8b;
    --GW-table-scrollbar-border-color: #fff;
    --GW-table-column-heading-hover-background-color: #2b3637;
    --GW-table-sorted-column-heading-background-color: #216983;
    --GW-table-sorted-column-heading-text-color: #000;
    --GW-table-sorted-column-heading-text-shadow-color: #fff;
    --GW-table-zebra-stripe-alternate-row-background-color: #252525;
    --GW-table-row-hover-outline-color: #fff;

    /*  Code blocks.
     */
    --GW-code-element-border-color: #606060;
    --GW-code-element-background-color: #1d1d1d;
    --GW-pre-element-border-color: #606060;
    --GW-pre-element-background-color: #1d1d1d;
    --GW-pre-element-scrollbar-track-color: #1d1d1d;
    --GW-pre-element-scrollbar-thumb-color: #5c5c5c;
    --GW-pre-element-scrollbar-thumb-hover-color: #8b8b8b;
    --GW-code-block-line-highlight-background-color: #171600;
    --GW-code-block-line-highlight-border-color: #494949;
    --GW-code-block-line-number-color: #7c7c7c;
    --GW-code-block-line-number-divider-color: #5c5c5c;


    /*  Syntax highlight theme.
     */
    --GW-syntax-highlight-color-normal: #f1edec;
    --GW-syntax-highlight-color-attribute: #b9e8ff;
    --GW-syntax-highlight-color-data-type: inherit;
    --GW-syntax-highlight-color-variable: #b4b4b4;
    --GW-syntax-highlight-color-other: inherit;
    --GW-syntax-highlight-color-preprocessor: inherit;
    --GW-syntax-highlight-color-extension: #a6a6a6;
    --GW-syntax-highlight-color-comment: #7f9c83;
    --GW-syntax-highlight-color-control-flow: #b4edaf;
    --GW-syntax-highlight-color-keyword: #b9e8ff;
    --GW-syntax-highlight-color-operator: #b9e8ff;
    --GW-syntax-highlight-color-special-char: #94adb6;
    --GW-syntax-highlight-color-built-in: #b9e8ff;
    --GW-syntax-highlight-color-function: #b9e8ff;
    --GW-syntax-highlight-color-constant: inherit;
    --GW-syntax-highlight-color-base-n: inherit;
    --GW-syntax-highlight-color-dec-val: inherit;
    --GW-syntax-highlight-color-float: inherit;
    --GW-syntax-highlight-color-information: inherit;
    --GW-syntax-highlight-color-char: inherit;
    --GW-syntax-highlight-color-string: inherit;
    --GW-syntax-highlight-color-verbatim-string: inherit;
    --GW-syntax-highlight-color-alert: #ff8470;
    --GW-syntax-highlight-color-error: #ff4a39;
    --GW-syntax-highlight-color-import: #a6a6a6;
    --GW-syntax-highlight-color-special-string: #b4b4b4;

    /*  Math.
     */
    --GW-math-block-background-color: #252525;
    --GW-math-block-background-color-flash: #000;
    --GW-math-block-scrollbar-border-color: #5c5c5c;
    --GW-math-block-scrollbar-thumb-color: #5c5c5c;
    --GW-math-block-scrollbar-thumb-hover-color: #8b8b8b;

    /*  Dropcaps.
     */
    --GW-dropcaps-goudy-color: #fff;
    --GW-dropcaps-yinit-color: #f9f9f9;
    --GW-dropcaps-yinit-text-shadow-color: #a6a6a6;
    --GW-dropcaps-de-zs-color: #efefef;
    --GW-dropcaps-cheshire-color: #f1f1f1;
    --GW-dropcaps-kanzlei-color: #f1f1f1;

    /*  Admonitions.
     */
    --GW-admonition-note-left-border-color: #929292;
    --GW-admonition-note-background-color: #4f4f4f;
    --GW-admonition-tip-left-border-color: #4f4f4f;
    --GW-admonition-tip-background-color: #303030;
    --GW-admonition-warning-left-border-color: #bdbdbd;
    --GW-admonition-warning-background-color: #8a8a8a;
    --GW-admonition-warning-text-color: #000;
    --GW-admonition-error-left-border-color: #e1e1e1;
    --GW-admonition-error-background-color: #bdbdbd;
    --GW-admonition-error-text-color: #000;
    --GW-admonition-reversed-link-color: #494949;
    --GW-admonition-reversed-link-color-hover: #5c5c5c;
    --GW-admonition-reversed-link-underline-gradient-line-color: #5c5c5c;
    --GW-admonition-reversed-link-underline-gradient-line-color-hover: #6c6c6c;

	/*	Footer.
	 */
    --GW-bottom-ornament-line-color: #fff;

	/*	Pop-frames (popups or popins).
	 */
    --GW-popframes-object-popframe-background-color: #000;

    --GW-extracts-options-dialog-backdrop-background-color: rgba(0, 0, 0, 0.95);
    --GW-extracts-options-dialog-background-color: var(--GW-body-background-color);
    --GW-extracts-options-dialog-border-color: #7c7c7c;
    --GW-extracts-options-dialog-box-shadow-color: #cecece;
    --GW-extracts-options-dialog-horizontal-rule-color: #5c5c5c;
    --GW-extracts-options-dialog-button-background-color: var(--GW-body-background-color);
    --GW-extracts-options-dialog-button-text-color: #fff;
    --GW-extracts-options-dialog-button-border-color: #fff;
    --GW-extracts-options-dialog-button-hover-box-shadow-color: #fff;
    --GW-extracts-options-dialog-option-button-explanation-text-color: #a6a6a6;
    --GW-extracts-options-dialog-option-button-hover-text-color: #a6a6a6;
    --GW-extracts-options-dialog-radio-button-border-color: #fff;

    /*  Popups.
     */
    --GW-popups-popup-background-color: var(--GW-body-background-color);

    --GW-popups-popup-border-color: #5c5c5c;
    --GW-popups-popup-box-shadow-color: #5c5c5c;
    --GW-popups-popup-border-focused-color: #7c7c7c;
    --GW-popups-popup-box-shadow-focused-color: #7c7c7c;

    --GW-popups-popup-title-bar-background-color: #000;
    --GW-popups-popup-title-bar-button-color: #6c6c6c;
    --GW-popups-popup-title-bar-button-color-hover: #fff;
    --GW-popups-popup-title-bar-button-color-disabled: #333;
	--GW-popups-popup-title-color: #7c7c7c;
    --GW-popups-popup-title-link-hover-color: var(--GW-body-link-hover-color);
    --GW-popups-popup-title-bar-button-focused-color: #a6a6a6;
    --GW-popups-popup-title-bar-button-focused-color-hover: #fff;
    --GW-popups-popup-title-bar-button-focused-color-disabled: #494949;
    --GW-popups-popup-title-bar-submenu-box-shadow-color: #494949;
	--GW-popups-popup-title-focused-color: #fff;
    --GW-popups-popup-title-link-hover-focused-color: var(--GW-body-link-hover-color);

    --GW-popups-popup-scrollbar-thumb-color: #494949;
    --GW-popups-popup-scrollbar-thumb-hover-color: #6c6c6c;
    --GW-popups-popup-scrollbar-thumb-focused-color: #5c5c5c;
    --GW-popups-popup-scrollbar-thumb-hover-focused-color: #8b8b8b;

    /*  Popins.
     */
    --GW-popins-popin-background-color: var(--GW-body-background-color);

    --GW-popins-popin-border-color: #7c7c7c;
    --GW-popins-popin-backdrop-color: rgba(255, 255, 255, 0.4);
    --GW-popins-popin-box-shadow-color: #7c7c7c;

    --GW-popins-popin-title-bar-background-color: #000;
    --GW-popins-popin-title-bar-button-color: #a6a6a6;

    --GW-popins-popin-scrollbar-thumb-color: #5c5c5c;
    --GW-popins-popin-scrollbar-thumb-hover-color: #8b8b8b;

    --GW-popins-popin-stack-counter-text-color: #000;
    --GW-popins-popin-stack-counter-background-color: #6c6c6c;

    /*  Image focus.
     */
    --GW-image-focus-image-hover-drop-shadow-color: #a6a6a6;

	/*	Page toolbar.
	 */
    --GW-page-toolbar-border-color: #7c7c7c;
	--GW-page-toolbar-control-button-color: #7c7c7c;
	--GW-page-toolbar-control-button-active-color: #fff;

	/*	Page toolbar widgets.
	 */
	--GW-page-toolbar-button-icon-color: #7c7c7c;
	--GW-page-toolbar-button-selectable-icon-color: #404040;
	--GW-page-toolbar-button-selected-icon-color: #a6a6a6;
    --GW-page-toolbar-button-text-color: #b4b4b4;
    --GW-page-toolbar-button-disabled-text-color: #5c5c5c;
    --GW-page-toolbar-button-highlighted-text-color: #fff;

	/*	Reader mode.
	 */
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-background-color: rgba(255, 255, 255, 0.8);
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-text-color: #000;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-text-shadow-color: #fff;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-key-icon-border-color: #6c6c6c;
	--GW-reader-mode-masked-links-key-toggle-info-alert-panel-key-icon-background-color: #cecece;

	/*	‚ÄúBack to top‚Äù link.
	 */
	--GW-back-to-top-link-color: #5c5c5c;
	--GW-back-to-top-link-hover-color: #8b8b8b;

	/*	Mobile floating header.
	 */
	--GW-floating-header-box-shadow-color: #5c5c5c;
	--GW-floating-header-scroll-indicator-color: #8b8b8b;

	/*	‚ÄúSkip to content‚Äù accessibility link.
	 */
	--GW-skip-to-content-text-color: #000;
	--GW-skip-to-content-border-color: #000;
	--GW-skip-to-content-background-color: #ff847b;

	/*	Nav header.
	 */
	--GW-nav-header-link-color: #999;
	--GW-nav-header-link-hover-color: #fff;

	/*	X of the day.
	 */
	--GW-x-of-the-day-border-color: #5c5c5c;
}
:root {
    /*  Adjust background color to prevent pixels from turning off (contrary to 
    	popular belief, pixels turning off saves trivial energy, like <1% in 
    	measurements, and causes nasty scrolling/update jank due to delay in 
    	pixels turning back on), and improve contrast with the white.
     */
    --GW-body-background-color: #161616;

    /*  Dial back from pure white to keep contrast from being *too* high & 
    	‚Äòstark‚Äô (#fff bg / #000 text seems to work in light mode, but not in 
    	dark mode, perhaps because of differences in lighting environment?)
     */
    --GW-body-text-color: #f1f1f1;

    --GW-popups-popup-title-bar-pattern: var(--GW-image-pattern-dotted-161616-on-252525-2x-gif);
    --GW-popups-popup-title-bar-pattern-focused: var(--GW-image-pattern-dotted-161616-on-3e3e3e-2x-gif);

    --GW-popins-popin-backdrop-color: rgba(0, 0, 0, 0.6);

    --GW-popins-popin-title-bar-button-color: #bbb;

    --GW-checkerboard-scrollbar-background-image: var(--GW-image-checkerboard-888-000-2x-gif);
    --GW-checkerboard-scrollbar-hover-background-image: var(--GW-image-checkerboard-bfbfbf-000-2x-gif);
}

.dark-mode-invert,
.dark-mode-invert::before,
.dark-mode-invert::after {
	filter: var(--dark-mode-invert-filter, none);
}

/*  Admonition icons.
 */
div.admonition.tip::before {
    filter: invert(1);
}
div.admonition.note::before {
    filter: none;
}
div.admonition.warning::before {
    filter: none;
}
div.admonition.error::before {
    filter: none;
}

/*  SVG icons in the two darker styles of admonitions.
 */
div.admonition.warning a[data-link-icon-type='svg'] .link-icon-hook::after,
div.admonition.error a[data-link-icon-type='svg'] .link-icon-hook::after {
    filter: none;
}

/*  For sortable table column headings, we use dark versions of the up/down/both
    arrow icons.
 */
table th.tablesorter-header {
    background-image: url('/static/img/tablesorter/tablesorter-bg-dark.gif');
}
table th.tablesorter-headerAsc {
    background-image: url('/static/img/tablesorter/tablesorter-asc-dark.gif');
}
table th.tablesorter-headerDesc {
    background-image: url('/static/img/tablesorter/tablesorter-desc-dark.gif');
}

/*  Images that are marked as '.invert' by the server are inverted,
    hue-rotated, and desaturated. Other (non-invertible) images are merely
    desaturated. Hovering over an image restores it to its original state.
    Hierarchy: ‚Äò.invert-not‚Äô/‚Äò.invert-not-auto‚Äô: no inversion or grayscale;
    ‚Äò.invert‚Äô/‚Äò.invert-auto‚Äô: inverted (uninverted upon mouse hover);
    none: grayscaled (ungrayscaled on hover).
 */
figure img.invert,
figure img.invert-auto {
    filter: grayscale(50%) invert(100%) brightness(95%) hue-rotate(180deg);
}
figure img:not(.invert):not(.invert-auto) {
    filter: grayscale(50%);
}
figure img,
figure img.invert,
figure img.invert-auto {
    transition: filter 0.25s ease;
}
figure img:not(.drop-filter-on-hover-not):hover,
figure img:not(.drop-filter-on-hover-not).invert:hover,
figure img:not(.drop-filter-on-hover-not).invert-auto:hover,
figure img:not(.drop-filter-on-hover-not):not(.invert):not(.invert-auto):hover {
    filter: none;
    transition: filter 0s ease 0.25s;
}

figure img[src$=".svg"].invert:hover,
figure img[src$=".svg"].invert-auto:hover {
    filter: grayscale(50%) invert(100%) brightness(95%) hue-rotate(180deg);
}

/*  Image alt-text.
 */
figure img.invert::before,
figure img.invert-auto::before {
    filter: invert(1);
}
figure img.invert:hover::before,
figure img.invert-auto:hover::before {
    filter: none;
}
/*  Styling the image alt-text interferes with the transitions in dark mode.
    (We include non-class‚Äôd `img` in this selector for consistency.)

    TEMPORARY until we transition to a color-based instead of filter-based
    scheme for this. ‚ÄîSA 2022-07-29
 */
figure img,
figure img:hover,
figure img.invert,
figure img.invert:hover,
figure img.invert-auto,
figure img.invert-auto:hover {
    transition: none;
}

/*  For images which have been marked up (manually or automatically) with 
	‚Äò.invert-not‚Äô, we avoid any filtering at all. If they are manually marked up
	(artwork, diagrams with multiple subtly-different colors matched to a 
	legend/caption), the color is important and shouldn‚Äôt be faded out by 
	default. (Or invertOrNot has judged the image to be non-invertible, which
	presumably means something like the above also.)
 */
#markdownBody figure img.invert-not,
#markdownBody figure img.invert-not-auto {
    filter: none;
}

/*  The loading spinner for object popups (image, iframe, object) is inverted
    and made more visible in dark mode.
 */
.popframe.loading::before {
    filter: invert(1);
    opacity: 0.4;
}

/*  ‚ÄúLoading failed‚Äù messages for object popups.
 */
.popframe.loading-failed::after {
    opacity: 0.4;
}

/*  Masked links key toggle info alert panel.
 */
div#masked-links-key-toggle-info-alert img {
    filter: drop-shadow(0 0 3px var(--GW-reader-mode-masked-links-key-toggle-info-alert-panel-text-shadow-color));
}

/*  Recently-modified icon, manicule.
 */
.has-recently-modified-icon .recently-modified-icon-hook::before,
.manicule svg {
    filter: invert(1);
}

/*	Poem caesura marks.
 */
div.poem span.caesura-mark {
	opacity: 0.3;
}
@media all and (max-width: 649px) {
	div.poem span.caesura-mark {
		opacity: 0.4;
	}
}
</style>
<link rel="stylesheet" href="/static/css/head.css?v=1770514858">
<script src="/static/js/head.js?v=1770514858"></script>
<link rel="preload" href="/static/img/icon/icons.svg?v=1768170615" as="image">


  
  <!-- Hint at necessary third-party domains -->
  <link rel="preconnect" href="https://www.googletagmanager.com">

  <meta name="title" content="Archiving URLs">
  <meta name="citation_title" content="Archiving URLs">
  <meta name="og:title" content="Archiving URLs">
  <meta name="twitter:title" content="Archiving URLs">
  <meta name="generator" content="https://github.com/gwern/gwern.net/">
  <meta name="creator" content="gwern.net">
  
  <meta name="author" content="Gwern">
  <meta name="citation_author" content="Gwern">
  
  <meta name="contact" content="https://gwern.net/me#contact">
  <link rel="index" title="Gwern.net homepage" href="https://gwern.net/index">
  <link href="https://gwern.substack.com/feed" type="application/rss+xml" rel="alternate" title="ATOM/RSS feed of Gwern.net newsletters with additions and links.">

  <meta name="twitter:creator" content="gwern">
  <meta name="twitter:site" content="gwern.net">
  <meta name="og:site" content="gwern.net">
  <meta name="og:type" content="article">
  <meta name="description" content="Archiving the Web, because nothing lasts forever - pulling together all the previous archive tools.">
  <meta name="og:description" content="Archiving the Web, because nothing lasts forever - pulling together all the previous archive tools.">
  <meta property="og:image" content="https://gwern.net/static/img/logo/logo-whitebg-large-border.png">
  <meta property="og:image:alt" content="Default thumbnail text: the Gwern.net site logo, a logotype of a large blackletter fraktur capital letter 'G' on a white background.">
  <meta property="og:image:height" content="530">
  <meta property="og:image:width" content="441">
  <meta property="gwern:thumbnail:css-classes" content="">
  <meta name="keywords" content="">
  <meta name="dc.date.issued" content="10 Mar 2011">
  
  <meta name="citation_publication_date" content="10 Mar 2011">
  <meta name="dcterms.modified" content="">
  <link rel="schema.dcterms" href="https://www.dublincore.org/specifications/dublin-core/dcmi-terms/">
  <meta name="dcterms.rights" content="CC PD-0">
  <meta name="dc.rights" content="https://creativecommons.org/publicdomain/zero/1.0/">
  <link rel="canonical" href="https://gwern.net/Archiving-URLs">
  <meta name="citation_fulltext_html_url" content="https://gwern.net/Archiving-URLs">
  <meta name="og:url" content="https://gwern.net/Archiving-URLs">
  <link rel="alternate" type="text/markdown" href="https://gwern.net/Archiving-URLs.md" title="Markdown source of ‚ÄòArchiving URLs‚Äô page"> <!-- Also available via Accept header -->
  <meta name="page-body-classes" content="page-archiving urls dropcaps-de-zs">
  <meta name="citation_fulltext_world_readable" content="">
  <meta name="color-scheme" content="light dark">

  
  <title>Archiving URLs ¬∑ Gwern.net</title>
  

  <link id="favicon" rel="icon" type="image/png" href="/static/img/logo/logo-favicon-small.png">
  <link id="favicon-dark" rel="icon" type="image/png" href="/static/img/logo/logo-favicon-small-dark.png" media="all and (prefers-color-scheme: dark)">
  <link id="favicon-apple-touch" rel="apple-touch-icon" type="image/png" href="/static/img/logo/logo-favicon-appletouch.png">
  <link id="favicon-apple-touch-dark" rel="apple-touch-icon" type="image/png" href="/static/img/logo/logo-favicon-appletouch-dark.png" media="all and (prefers-color-scheme: dark)">

  <!-- CSS for JS-disabled users: ensure that NoScripters know what they are missing even if they jump to a section & miss the warning at top/bottom. -->
  <noscript>
    <style>
      #markdownBody #noscript-warning-header {
          position: fixed; /* sticky */
          top: 6px; /* at top */
          width: 58%;
          z-index: 99; /* Make sure it is on top */
          background-color: #f8f8f8; /* Set a solid background color so legible while positioned over text */
          border-color: var(--GW-abstract-border-color); /* Make look like theme-toggle/admonitions a bit more */
          border-width: 6px 6px 6px 6px;
          border-style: double;
      }
      #markdownBody #noscript-warning-header p { margin: 10px; }
      nav#navbar { padding-top: 160px; } /* avoid overlap with page header */
    </style>
  </noscript>
</head>

<body class="page-archiving urls dropcaps-de-zs">
  <!-- Inlined asset links (no SSI): injected by Hakyll from static/include/inlined-asset-links.html -->
  <link rel="stylesheet" href="/static/css/style.css?v=1770491984" media="print" onload="this.media=`all`">
<script src="/static/js/script.js?v=1770491982" defer></script>


  <main>
    <a id="skip-to-content-link" href="#markdownBody">Skip to main content</a>

    <!-- Navbar (no SSI): injected by Hakyll from static/include/navbar.html -->
        <nav id="navbar">
      <a class="logo" rel="home me contents" href="/index" accesskey="\" title="Homepage: categorized list of articles index"><svg class="logo-image" viewbox="0 0 64 75">
      <use href="/static/img/logo/logo-smooth.svg#logo"></use></svg></a>
      <div class="navbar-links">
        <a class="site link-page link-annotated" href="/about" title="Site ideals, source, content, traffic, examples, license" rel="author">Site</a>
        <a class="design link-page link-annotated" href="/design" title="Design and implementation notes">Design</a>
        <a class="new link-page link-annotated" href="/changelog" title="Changelog of what‚Äôs new or updated">New</a>
        <a class="blog link-page" href="/blog/index" title="Shortform Gwern writings">Blog</a>
        <a class="links link-page" href="/Links" title="Links page">Links</a>
        <a class="patreon" href="https://www.patreon.com/gwern" title="Link to Patreon donation profile to support my writing" rel="me">Patreon</a>
        <a class="mail" href="https://gwern.substack.com/" title="Monthly mailing list: newsletter signup form" rel="me">Substack</a>
      </div>
    </nav>


    <article>

      <header>
        <h1>Archiving URLs</h1>
      </header>

      
      <div class="markdownBody" id="page-metadata">
          
        <div class="page-description"><p>Archiving the Web, because nothing lasts forever - pulling together all the previous archive tools.</p></div>
        <div class="page-metadata-fields">
            
            
            <span class="page-status" title="Writing status of current page: ranges 'abandoned'/'notes'/'draft'/'in progress'/'finished'"><em><span class="completion-status" data-progress-percentage="100">finished</span></em></span>
            <span class="page-confidence"><a href="/about#confidence-tags" title="Explanation of 'confidence' metadata: probability of overall being meaningfully correct, expressed as Kesselman Estimative Words (ranging 0‚Äì100%: 'certain'/'highly likely'/'likely'/'possible'/'unlikely'/'highly unlikely'/'remote'/'impossible')">certainty</a>: <em><span class="completion-status" data-progress-percentage="84">highly likely</span></em></span>
            <span class="page-importance"><a href="/about#importance-tags" title="Explanation of 'importance' metadata: rating 1‚Äì10 about how much a topic matters to the world.">importance</a>: <em>0</em></span>
            
            
            
        </div>
      </div>
      

      <div id="TOC" class="TOC"><ul>
<li><a href="#link-rot" id="toc-link-rot">Link Rot</a></li>
<li><a href="#detection" id="toc-detection">Detection</a></li>
<li><a href="#prevention" id="toc-prevention">Prevention</a>
<ul>
<li><a href="#remote-caching" id="toc-remote-caching">Remote Caching</a></li>
<li><a href="#local-caching" id="toc-local-caching">Local Caching</a>
<ul>
<li><a href="#url-sources" id="toc-url-sources">URL Sources</a>
<ul>
<li><a href="#browser-history" id="toc-browser-history">Browser History</a></li>
<li><a href="#document-links" id="toc-document-links">Document Links</a></li>
<li><a href="#website-spidering" id="toc-website-spidering">Website Spidering</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#reacting-to-broken-links" id="toc-reacting-to-broken-links">Reacting to Broken Links</a></li>
<li><a href="#external-links" id="toc-external-links">External Links</a></li>
<li><a href="#appendices" id="toc-appendices">Appendices</a>
<ul>
<li><a href="#filter-urls" id="toc-filter-urls"><code>filter-urls</code></a></li>
<li><a href="#sort---key-compression-trick" id="toc-sort---key-compression-trick"><code>sort --key</code> Compression Trick</a>
<ul>
<li><a href="#locality" id="toc-locality">Locality</a></li>
<li><a href="#web-archives" id="toc-web-archives">Web Archives</a></li>
<li><a href="#separate-mirrors" id="toc-separate-mirrors">Separate Mirrors</a></li>
<li><a href="#alternatives" id="toc-alternatives">Alternatives</a></li>
<li><a href="#external-links-1" id="toc-external-links-1">External Links</a></li>
</ul></li>
</ul></li>
</ul></div> <div id="markdownBody" class="markdownBody"><blockquote>
<p>‚ÄúDecay is inherent in all compound things. Work out your own salvation with diligence.‚Äù ‚ÄìLast words of the Buddha</p>
</blockquote>
<p>Given my interest in <a href="About#long-content" id="_Q-inheQy">long term content</a> and extensive linking, <a href="https://en.wikipedia.org/wiki/Link_rot" id="_x9z7UoG_" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Link_rot#bodyContent">link rot</a> is an issue of deep concern to me. I need backups not just for my files<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, but for the web pages I read and use - they‚Äôre all part of my <a href="https://en.wikipedia.org/wiki/Extended_mind_thesis#%22The_Extended_Mind%22" id="_8U5f_s5o" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Extended_mind_thesis#bodyContent">exomind</a>. It‚Äôs not much good to have an extensive essay on some topic where half the links are dead and the reader can neither verify my claims nor get context for my claims.</p>
<section id="link-rot" class="level1">
<h1><a href="#link-rot" title="Link to section: ¬ß &#39;Link rot&#39;">Link Rot</a></h1>
<p>The dimension of digital decay is dismal and distressing. <a href="https://en.wikipedia.org/wiki/Link_rot#Prevalence" id="_asnrhUkc" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Link_rot#bodyContent">Wikipedia</a>:</p>
<blockquote>
<p>In a <span class="date-range">2003<sub><span title="2003 was 23 years ago.">23ya</span></sub></span> experiment, <a href="http://www2003.org/cdrom/papers/refereed/p097/P97%20sources/p97-fetterly.html" id="_V9EG_ofA">Fetterly et al.</a> discovered that about one link out of every 200 disappeared each week from the Internet. <a href="http://iwaw.europarchive.org/05/papers/iwaw05-mccown1.pdf" id="_dhLJmmPT" data-link-icon="internet-archive" data-link-icon-type="svg">McCown et al. (<span class="date-range">2005<sub><span title="2005 was 21 years ago.">21ya</span></sub></span>)</a> discovered that half of the URLs cited in <a href="https://en.wikipedia.org/wiki/D-Lib_Magazine" id="_iN2nnE_X" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/D-Lib_Magazine#bodyContent">D-Lib Magazine</a> articles were no longer accessible 10 years after publication [the irony!], and other studies have shown link rot in academic literature to be even worse (<a href="http://www.spinellis.gr/pubs/jrnl/2003-CACM-URLcite/html/urlcite.html" id="_G00gVlzE">Spinellis, 2003</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.9695&amp;rep=rep1&amp;type=pdf" id="_1DVA3xiJ" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02">Lawrence et al., 2001</a>). <a href="http://www.dlib.org/dlib/january02/nelson/01nelson.html" id="_tedsShQL">Nelson and Allen (<span class="date-range">2002<sub><span title="2002 was 24 years ago.">24ya</span></sub></span>)</a> examined link rot in digital libraries and found that about 3% of the objects were no longer accessible after one year.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Bruce_Schneier" id="_pIHgdlcC" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Bruce_Schneier#bodyContent">Bruce Schneier</a> remarks that one friend experienced 50% linkrot in one of his pages over less than 9 years (not that the situation was any better <a href="http://www.pantos.org/atw/35654.html" id="_ZB4TzXwr">in 1998</a>), and that his own blog posts link to news articles that go dead in days<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>; the <a href="https://en.wikipedia.org/wiki/Internet_Archive" id="_ECwLZp68" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Internet_Archive#bodyContent">Internet Archive</a> has estimated the average lifespan of a Web page at <a href="https://web.archive.org/web/20071019225237/http://www.wired.com/culture/lifestyle/news/2001/10/47894" id="_cFiNyRlh" class="link-live" data-link-icon="internet-archive" data-link-icon-type="svg" data-url-iframe="https://web.archive.org/web/20071019225237if_/http://www.wired.com/culture/lifestyle/news/2001/10/47894" title="Wayback Goes Way Back on Web">100 days</a>. A <em><a href="https://en.wikipedia.org/wiki/Science_(journal)" id="_5idGVcCN" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Science_(journal)#bodyContent">Science</a></em> study looked at articles in prestigious journals; they didn‚Äôt use many Internet links, but when they did, 2 years later ~13% were dead<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The French company Linterweb studied external links on the <a href="https://en.wikipedia.org/wiki/French_Wikipedia" id="_0iDXeCO5" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/French_Wikipedia#bodyContent">French Wikipedia</a> before setting up <a href="http://www.wikiwix.com/" id="_EGGx1Nq7">their cache</a> of French external links, and found - back in <span class="date-range">2008<sub><span title="2008 was 18 years ago.">18ya</span></sub></span> - already <a href="http://fr.wikipedia.org/wiki/Utilisateur:Pmartin/Cache" id="_0xN7e4tE" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="http://fr.m.wikipedia.org/wiki/Utilisateur:Pmartin/Cache#bodyContent">5% were dead</a><span>. (The English Wikipedia has seen a <span class="date-range" title="The date range 2010‚Äì2011 lasted 1 year, ending 15 years ago.">2010‚Äì2011<sub><span title="2010 was 16 years ago.">15ya</span></sub></span> spike from a few thousand dead links to </span><a href="https://en.wikipedia.org/wiki/File:Articles-w-Dead-Links-Jan-2011.png" id="_U8lT5na9" class="content-transform-not link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/File:Articles-w-Dead-Links-Jan-2011.png#bodyContent">~110,000</a> out of <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_External_links/Webcitebot2#Summary" id="_fk_ofv8_" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Wikipedia_talk:WikiProject_External_links/Webcitebot2#bodyContent">~17.5m live links</a>.) The dismal studies <a href="http://jnci.oxfordjournals.org/content/96/12/969.full" id="_zFwLgNO2" data-link-icon="OUP" data-link-icon-type="text,tri" data-link-icon-color="#011d3f" title="&#39;Internet Citations in Oncology Journals: A Vanishing Resource?&#39;, Hester et al 2004">just</a> <a href="/docs/2007-dimitrova.pdf" id="dimitrova-bugeja-2007" class="link-modified-recently" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02" title="&#39;The half-life of internet references cited in communication journals&#39;, Dimitrova &amp; Bugeja 2007">go</a> <a href="/docs/2008-wren.pdf" id="wren-2008" class="link-modified-recently" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02" title="&#39;URL decay in MEDLINE - a 4-year follow-up study&#39;, Wren 2008">on</a> <a href="http://archderm.ama-assn.org/cgi/reprint/142/9/1147.pdf" id="_Bgff4GRA" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02" title="&#39;Uniform Resource Locator Decay in Dermatology Journals: Author Attitudes and Preservation Practices&#39;, Wren et al 2006">and</a> <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2213465/" id="_xnnD67GP" data-link-icon="nlm-ncbi" data-link-icon-type="svg" data-link-icon-color="#20558a" title="&#39;The Prevalence and Inaccessibility of Internet References in the Biomedical Literature at the Time of Publication&#39;, Aronsky et al 2007">on</a> <a href="http://yjolt.org/sites/default/files/Something_Rotten_in_Legal_Citation.pdf" id="_Wk3CQhwf" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02" title="&#39;Something Rotten in the State of Legal Citation: the Life Span of a United States Supreme Court Citation Containing an Internet Link (1996-2010)&#39;, Liebler &amp; Liebert 2013">and</a> <a href="http://www.fasebj.org/content/19/14/1943.full" id="_Rqk_lwrf" title="&#39;Unavailability of online supplementary scientific information from articles published in major journals&#39;, Evangelou et al 2005">on</a> (<a href="http://ijism.ricest.ac.ir/ojs/index.php/ijism/article/download/49/53" id="_oBPZWUgb" title="&#39;Availability and Half-life of Web References Cited in Information Research Journal: A Citation Study&#39;, Moghaddam et al 2012">and</a> <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2329161" id="_bYBZHpiE" data-link-icon="SSRN" data-link-icon-type="text,quad" data-link-icon-color="#007398" title="&#39;Perma: Scoping and Addressing the Problem of Link and Reference Rot in Legal Citations&#39;, Zittrain &amp; Albert 2013">on</a>). Even in a highly stable, funded, curated environment, link rot happens anyway. For example, about <a href="http://arxiv.org/pdf/1209.3026v1.pdf" id="_lHNbKs87" data-link-icon="ùõò" data-link-icon-type="text" data-link-icon-color="#b31b1b" title="&#39;Losing My Revolution: How Many Resources Shared on Social Media Have Been Lost?&#39;, SalahEldeen &amp; Nelson 2012">11% of Arab Spring-related tweets</a> were gone within a year (even though Twitter is - currently - still around).</p>
<p>My specific target date is 2070, 60 years from now. As of 10 March <span class="date-range">2011<sub><span title="2011 was 15 years ago.">15ya</span></sub></span>, <code>gwern.net</code><span> has around 6800 external links (with around 2200 to non-Wikipedia websites)</span><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a><span>. Even at the lowest estimate of 3% annual linkrot, few will survive to 2070. If each link has a 97% chance of surviving each year, then the chance a link will be alive in 2070 is </span><span class="math inline">\(0.97^{2070-2011} = ~0.16\)</span> (or to put it another way, an 84% chance any given link <em>will</em> die). The 95% <a href="https://en.wikipedia.org/wiki/Confidence_interval" id="_i_2OI0BT" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Confidence_interval#bodyContent">confidence interval</a> for such a <a href="https://en.wikipedia.org/wiki/Binomial_distribution" id="_0lE6Zs0R" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Binomial_distribution#bodyContent">binomial distribution</a><span> says that of the 2200 non-Wikipedia links, ~336-394 will survive to 2070</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. If we try to predict using a more reasonable estimate of 50% linkrot, then an average of 0 links will survive (<span class="math inline">\(0.50^{2070-2011} \times 2200 = 1.735 \times 10^{-16} \times 2200 \simeq 0\)</span>). It would be a good idea to simply assume that <em>no</em> link will survive.</p>
<p>With that in mind, one can consider remedies. (If we lie to ourselves and say it won‚Äôt be a problem in the future, then we guarantee that it <em>will</em> be a problem. <a href="http://wiki.lesswrong.com/wiki/Litany_of_Gendlin" id="_EEGijOA7" data-link-icon="LW" data-link-icon-type="text" data-link-icon-color="#7faf83" data-url-iframe="http://www.greaterwrong.com/wiki/Litany_of_Gendlin?format=preview&amp;theme=classic">‚ÄúPeople can stand what is true, for they are already enduring it.‚Äù</a>)</p>
</section>
<section id="detection" class="level1">
<h1><a href="#detection" title="Link to section: ¬ß &#39;Detection&#39;">Detection</a></h1>
<blockquote>
<p>With every new spring<br />
the blossoms speak not a word<br />
yet expound the Law ‚Äì<br />
knowing what is at its heart<br />
by the scattering storm winds.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</blockquote>
<p>The first remedy is to learn about broken links as soon as they happen, which allows one to react quickly and scrape archives or search engine caches (<a href="http://www.cs.odu.edu/~fmccown/research/lazy/" id="_YD34tFUn">‚Äòlazy preservation‚Äô</a>). I currently use <a href="http://wummel.github.io/linkchecker/" id="_8sVSlWXz"><code>linkchecker</code></a> to spider gwern.net looking for broken links. <code>linkchecker</code> is run in a <a href="https://en.wikipedia.org/wiki/Cron" id="_knMGVXrV" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Cron#bodyContent">cron</a> job like so:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">@monthly</span> linkchecker <span class="at">--check-extern</span> <span class="at">--timeout</span><span class="op">=</span>35 <span class="at">--no-warnings</span> <span class="at">--file-output</span><span class="op">=</span>html <span class="dt">\</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">--ignore-url</span><span class="op">=</span>^mailto <span class="at">--ignore-url</span><span class="op">=</span>^irc <span class="at">--ignore-url</span><span class="op">=</span>http://.<span class="pp">*</span><span class="dt">\.</span>onion <span class="dt">\</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">--ignore-url</span><span class="op">=</span>paypal.com <span class="at">--ignore-url</span><span class="op">=</span>web.archive.org <span class="dt">\</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                     http://www.gwern.net</span></code></pre></div>
<p>Just this command would turn up many false positives. For example, there would be several hundred warnings on Wikipedia links because I link to redirects; and <code>linkchecker</code> respects <a href="https://en.wikipedia.org/wiki/Robots.txt" id="_G_6MMZxB" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Robots.txt#bodyContent">robots.txt</a>s which forbid it to check liveness, but emits a warning about this. These can be suppressed by editing <code>~/.linkchecker/linkcheckerrc</code> to say <code>ignorewarnings=http-moved-permanent,http-robots-denied</code> (the available warning classes are listed in <code>linkchecker -h</code>).</p>
<p>The quicker you know about a dead link, the sooner you can look for replacements or its new home.</p>
</section>
<section id="prevention" class="level1">
<h1><a href="#prevention" title="Link to section: ¬ß &#39;Prevention&#39;">Prevention</a></h1>
<section id="remote-caching" class="level2">
<h2><a href="#remote-caching" title="Link to section: ¬ß &#39;Remote caching&#39;">Remote Caching</a></h2>
<p>We can ask a third party to keep a cache for us. There are several <a href="https://en.wikipedia.org/wiki/Archive_site" id="_dZzcviiL" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Archive_site#bodyContent">archive site</a> possibilities:</p>
<ol type="1">
<li><p>the <a href="https://en.wikipedia.org/wiki/Internet_Archive" id="_ECwLZp68" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Internet_Archive#bodyContent">Internet Archive</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/WebCite" id="_RHQYJnEy" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/WebCite#bodyContent">WebCite</a></p></li>
<li><p><a href="http://perma.cc/" id="_u59t1ZVI">Perma.cc</a></p></li>
<li><p>Linterweb‚Äôs WikiWix<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p></li>
<li><p><a href="http://www.peeep.us/" id="_EqSdFOCg">Peeep.us</a></p></li>
<li><p><a href="http://archive.is/" id="_sz5cVOCf" data-link-icon="internet-archive" data-link-icon-type="svg">Archive.is</a></p></li>
<li><p><a href="https://pinboard.in/" id="_kuIyxYmO" class="link-live">Pinboard</a> (with the $25/yr archiving option<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>)</p></li>
<li><p><a href="http://hiyo.jp/" id="_oHTS770t">Hiyo.jp</a> &amp; <a href="http://megalodon.jp/" id="_5Q96PnHN">Megalodon.jp</a> (may be difficult to use)</p></li>
</ol>
<p>There are other options but they are not available like Google<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> or various commercial/government archives<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p><!-- TODO: develop and cover Pinboard, Archive.is, and Peeep.us support --></p>
<p>(An example would be <a href="http://bits.blogs.nytimes.com/2010/12/07/palm-is-far-from-game-over-says-former-chief/" id="_z3Js0VWr" data-link-icon="new-york-times" data-link-icon-type="svg" title="Palm Is Far From &#39;Game Over&#39;, Says Former Chief"><code>bits.blogs.nytimes.com/2010/12/07/palm-is-far-from-game-over-says-former-chief/</code></a> being archived at <a href="http://webcitation.org/5ur7ifr12" id="_t-iN5U14" data-link-icon="internet-archive" data-link-icon-type="svg"><code>webcitation.org/5ur7ifr12</code></a>.)</p>
<p>My first program in this vein of thought was a bot which fired off WebCite and Internet Archive/Alexa requests: <a href="haskell/Wikipedia%20Archive%20Bot" id="_IpRWHDc2">Wikipedia Archiving Bot</a>, quickly followed up by a <a href="haskell/Wikipedia%20RSS%20Archive%20Bot" id="_kQVc3TZ5">RSS version</a>. (Or you could install the <a href="https://en.wikipedia.org/wiki/Alexa_Internet#Toolbar" id="_miFac4gP" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Alexa_Internet#bodyContent">Alexa Toolbar</a> to get automatic submission to the Internet Archive, if you have ceased to care about privacy.)</p>
<p>The core code was quickly adapted into a <a href="https://hackage.haskell.org/package/gitit" id="_GhXQP1Sn" class="link-live" data-link-icon="ùõå" data-link-icon-type="text" data-link-icon-color="#5e5086">gitit</a> wiki plugin which hooked into the save-page functionality and tried to archive every link in the newly-modified page, <a href="https://github.com/jgm/gitit/blob/master/plugins/Interwiki.hs" id="_FXREgGL4" data-link-icon="github" data-link-icon-type="svg">Interwiki.hs</a></p>
<p>Finally, I wrote <a href="https://hackage.haskell.org/package/archiver" id="_6gw78ILX" class="link-live" data-link-icon="ùõå" data-link-icon-type="text" data-link-icon-color="#5e5086">archiver</a>, a daemon which watches<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>/reads a text file. (Source is available via <code>git clone https://github.com/gwern/archiver-bot.git</code>.)</p>
<p>The library half of <code>archiver</code> is a simple wrapper around the appropriate HTTP requests; the executable half reads a specified text file and loops as it (slowly) fires off requests and deletes the appropriate URL.</p>
<p>That is, <code>archiver</code> is a daemon which will process a specified text file, each line of which is a URL, and will one by one request that the URLs be archived or spidered</p>
<p>Usage of <code>archiver</code> might look like <code>archiver ~/.urls.txt gwern@gwern.net</code>. In the past, <code>archiver</code> would sometimes crash for unknown reasons, so I usually wrap it in a <code>while</code> loop like so: <code>while true; do archiver ~/.urls.txt gwern@gwern.net; done</code>. If I wanted to put it in a detached <a href="https://en.wikipedia.org/wiki/GNU_Screen" id="_Fl8O5-9r" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/GNU_Screen#bodyContent">GNU screen</a> session: <code>screen  -d -m -S "archiver" sh -c 'while true; do archiver ~/.urls.txt gwern@gwern.net; done'</code>. Finally, rather than start it manually, I use a cron job to start it at boot, for a final invocation of</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">@reboot</span> sleep 4m <span class="kw">&amp;&amp;</span> <span class="ex">screen</span> <span class="at">-d</span> <span class="at">-m</span> <span class="at">-S</span> <span class="st">&quot;archiver&quot;</span> sh <span class="at">-c</span> <span class="st">&#39;while true; do archiver ~/.urls.txt gwern2@gwern.net \</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="st">        &quot;cd ~/www &amp;&amp; nice -n 20 ionice -c3 torify wget --unlink --limit-rate=20k --page-requisites --timestamping \</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="st">        -e robots=off --reject .iso,.exe,.gz,.xz,.rar,.7z,.tar,.bin,.zip,.jar,.flv,.mp4,.avi,.webm \</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="st">        --user-agent=&#39;</span>Firefox/4.9<span class="st">&#39;&quot; 200; done&#39;</span></span></code></pre></div>
</section>
<section id="local-caching" class="level2">
<h2><a href="#local-caching" title="Link to section: ¬ß &#39;Local caching&#39;">Local Caching</a></h2>
<p>Remote archiving, while convenient, has a major flaw: the archive services cannot keep up with the growth of the Internet and are woefully incomplete. I experience this regularly, where a link on <code>gwern.net</code> goes dead and I cannot find it in the Internet Archive or WebCite, and it is a general phenomenon: <a href="http://arxiv.org/pdf/1212.6177v1.pdf" id="_bf5N-wZM" data-link-icon="ùõò" data-link-icon-type="text" data-link-icon-color="#b31b1b" title="How Much of the Web Is Archived?"><span class="cite"><span class="cite-author-plural" title="et al">Ainsworth</span><span class="cite-joiner"> et al </span><span class="cite-date">2012</span></span></a> find &lt;35% of common Web pages ever copied into an archive service, and typically only one copy exists.</p>
<p>On a roughly monthly basis, I run a shell script named, imaginatively enough, <code>local-archiver</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/sh</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="at">-e</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cp</span> <span class="kw">`</span><span class="fu">find</span> ~/.mozilla/ <span class="at">-name</span> <span class="st">&quot;places.sqlite&quot;</span><span class="kw">`</span> ~/</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="ex">sqlite3</span> places.sqlite <span class="st">&quot;SELECT url FROM moz_places, moz_historyvisits </span><span class="dt">\</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="st">                       WHERE moz_places.id = moz_historyvisits.place_id </span><span class="dt">\</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="st">                             and visit_date &gt; strftime(&#39;%s&#39;,&#39;now&#39;,&#39;-1.5 month&#39;)*1000000 ORDER by </span><span class="dt">\</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="st">                       visit_date;&quot;</span> <span class="kw">|</span> <span class="ex">filter-urls</span> <span class="op">&gt;&gt;</span> ~/.tmp</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> ~/places.sqlite</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">split</span> <span class="at">-l500</span> ~/.tmp ~/.tmp-urls</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> ~/.tmp</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> file <span class="kw">in</span> ~/.tmp-urls<span class="pp">*</span><span class="kw">;</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a> <span class="cf">do</span> <span class="kw">(</span><span class="fu">wget</span> <span class="at">--unlink</span> <span class="at">--continue</span> <span class="at">--page-requisites</span> <span class="at">--timestamping</span> <span class="at">--input-file</span> <span class="va">$file</span> <span class="kw">&amp;&amp;</span> <span class="fu">rm</span> <span class="va">$file</span> <span class="kw">&amp;);</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="cf">done</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="fu">find</span> ~/www <span class="at">-size</span> +4M <span class="at">-delete</span></span></code></pre></div>
<p>The code is not the prettiest, but it‚Äôs fairly straightforward:</p>
<ul>
<li><p>the script grabs my Firefox browsing history by extracting it from the history SQL database file<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>, and feeds the URLs into <a href="https://en.wikipedia.org/wiki/Wget" id="_ZLAEchMp" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Wget#bodyContent">wget</a></p></li>
<li><p>The script <code>split</code>s the long list of URLs into a bunch of files and runs that many <code>wget</code>s because <code>wget</code> apparently has no way of simultaneously downloading from multiple domains.</p></li>
<li><p>The <a href="#filter-urls"><code>filter-urls</code></a> command is another shell script, which removes URLs I don‚Äôt want archived. This script is a hack which looks like this:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/sh</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="at">-e</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> /dev/stdin <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">&quot;s/#.*//&quot;</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">&quot;s/&amp;sid=.*$//&quot;</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">&quot;s/\/$//&quot;</span> <span class="kw">|</span> <span class="fu">grep</span> <span class="at">-v</span> <span class="at">-e</span> 4chan <span class="at">-e</span> reddit ...</span></code></pre></div></li>
</ul>
<p>A local copy is not the best resource - what if a link goes dead in a way your tool cannot detect so you don‚Äôt <em>know</em> to put up your copy somewhere? But it solves the problem pretty decisively.</p>
<p><code>archiver</code> has an extra feature where any third argument is treated as an arbitrary <code>sh</code> command to run after each URL is archived, to which is appended said URL. You might use this feature if you wanted to load each URL into Firefox, or append them to a log file, or simply download or archive the URL in some other way.</p>
<p>For example, in conjunction with the big <code>local-archiver</code> runs, I have <code>archiver</code> run <code>wget</code> on each individual URL: <code>screen  -d -m -S "archiver" sh -c 'while true; do archiver ~/.urls.txt gwern@gwern.net "cd ~/www &amp;&amp; wget --unlink --continue --page-requisites --timestamping -e robots=off --reject .iso,.exe,.gz,.xz,.rar,.7z,.tar,.bin,.zip,.jar,.flv,.mp4,.avi,.webm --user-agent='Firefox/3.5' 120"; done'</code>.</p>
<p>Alternately, you might use <code>curl</code> or a specialized archive downloader like the Internet Archive‚Äôs crawler <a href="http://crawler.archive.org/" id="_Yh8kdCx2" data-link-icon="internet-archive" data-link-icon-type="svg">Heritrix</a>.</p>
<p>The space consumed by such a backup is not that bad; only 30-50 gigabytes for a year of browsing, and less depending on how hard you prune the downloads. (More, of course, if you use <code>linkchecker</code> to archive entire sites and not just the pages you visit.) Storing this is quite viable in the long term; while page sizes have <a href="http://www.websiteoptimization.com/speed/tweak/average-web-page/" id="_dTIZqUgJ">increased 7x</a> between <span class="date-range">2003<sub><span title="2003 was 23 years ago.">23ya</span></sub></span> and <span class="date-range">2011<sub><span title="2011 was 15 years ago.">15ya</span></sub></span> and pages average around 400kb<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, <a href="https://en.wikipedia.org/wiki/Mark_Kryder#Kryder%27s_law_projection" id="_ZqWbh0pr" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Mark_Kryder#bodyContent">Kryder‚Äôs law</a> has also been operating and has increased disk capacity by ~128x - in 2011, $80 will buy you at least <a href="http://forre.st/storage#hdd" id="_LLtN0t58">2 terabytes</a>, that works out to 4 cents a gigabyte or 80 cents for the low estimate for downloads; that is much better than the $25 annual fee that somewhere like <a href="http://pinboard.in/upgrade/" id="_x4HQrnk8">Pinboard</a> charges. Of course, you need to back this up yourself. We‚Äôre relatively fortunate here - most Internet documents are ‚Äòborn digital‚Äô and easy to migrate to new formats or inspect in the future. We can download them and worry about how to view them only when we need a particular document, and Web browser backwards-compatibility already stretches back to files written in the early 1990s. (Of course, we‚Äôre probably screwed if we discover the content we wanted was presented only in Adobe Flash or as an inaccessible ‚Äòcloud‚Äô service.) In contrast, if we were trying to preserve programs or software libraries instead, we would face a much more formidable task in keeping a working ladder of binary-compatible virtual machines or interpreters<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. The situation with <a href="http://www.davidbordwell.net/blog/2012/02/13/pandoras-digital-box-pix-and-pixels/" id="_vunEDtk0" title="Pandora&#39;s digital box: Pix and pixels">digital movie preservation</a> hardly bears thinking on.</p>
<p>There are ways to cut down on the size; if you tar it all up and run <a href="https://en.wikipedia.org/wiki/7-Zip" id="_ZwCgqN4_" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/7-Zip#bodyContent">7-Zip</a> with maximum compression options, you could probably compact it to 1/5th the size. I found that the uncompressed files could be reduced by around 10% by using <a href="https://en.wikipedia.org/wiki/Fdupes" id="_cKMAfNlr" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Fdupes#bodyContent">fdupes</a> (<a href="http://netdial.caribe.net/~adrian2/fdupes.html" id="_SuWrOL3h">homepage</a>) to look for duplicate files and turning the duplicates into a space-saving <a href="https://en.wikipedia.org/wiki/Hard_link" id="_Yh13EzQ8" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Hard_link#bodyContent">hard link</a> to the original with a command like <code>fdupes --recurse --hardlink ~/www/</code>. (Apparently there are a <em>lot</em> of bit-identical JavaScript (eg. <a href="https://en.wikipedia.org/wiki/JQuery" id="_XUvzcXBB" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/JQuery#bodyContent">JQuery</a>) and images out there.)</p>
<section id="url-sources" class="level3">
<h3><a href="#url-sources" title="Link to section: ¬ß &#39;URL sources&#39;">URL Sources</a></h3>
<section id="browser-history" class="level4">
<h4><a href="#browser-history" title="Link to section: ¬ß &#39;Browser history&#39;">Browser History</a></h4>
<p>There are a number of ways to populate the source text file. For example, I have a script <code>firefox-urls</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/sh</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="at">-e</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cp</span> <span class="at">--force</span> <span class="kw">`</span><span class="fu">find</span> ~/.mozilla/firefox/ <span class="at">-name</span> <span class="st">&quot;places.sqlite&quot;</span><span class="kw">|</span><span class="fu">sort</span><span class="kw">|</span><span class="fu">head</span> <span class="at">-1</span><span class="kw">`</span> ~/</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="ex">sqlite3</span> <span class="at">-batch</span> places.sqlite <span class="st">&quot;SELECT url FROM moz_places, moz_historyvisits </span><span class="dt">\</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="st">                       WHERE moz_places.id = moz_historyvisits.place_id and </span><span class="dt">\</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="st">                       visit_date &gt; strftime(&#39;%s&#39;,&#39;now&#39;,&#39;-1 day&#39;)*1000000 ORDER by </span><span class="dt">\</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="st">                       visit_date;&quot;</span> <span class="kw">|</span> <span class="ex">filter-urls</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> ~/places.sqlite</span></code></pre></div>
<p>(<code>filter-urls</code> is the same script as in <code>local-archiver</code>. If I don‚Äôt want a domain locally, I‚Äôm not going to bother with remote backups either. In fact, because of WebCite‚Äôs rate-limiting, <code>archiver</code> is almost perpetually back-logged, and I <em>especially</em> don‚Äôt want it wasting time on worthless links like <a href="https://en.wikipedia.org/wiki/4chan" id="_vsu6CTu3" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/4chan#bodyContent">4chan</a>.)</p>
<p>This is called every hour by <code>cron</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">@hourly</span> firefox-urls <span class="op">&gt;&gt;</span> ~/.urls.txt</span></code></pre></div>
<p>This gets all visited URLs in the last time period and prints them out to the file for archiver to process. Hence, everything I browse is backed-up through <code>archiver</code>.</p>
<p>Non-Firefox browsers can be supported with similar strategies; for example, Zachary Vance‚Äôs Chromium scripts likewise extracts URLs from Chromium‚Äôs <a href="https://github.com/vanceza/rip-chrome-history" id="_pL4aZohc" data-link-icon="github" data-link-icon-type="svg">SQL history</a> &amp; <a href="https://github.com/vanceza/export-chrome-bookmarks" id="_aig415l5" data-link-icon="github" data-link-icon-type="svg">bookmarks</a>.</p>
</section>
<section id="document-links" class="level4">
<h4><a href="#document-links" title="Link to section: ¬ß &#39;Document links&#39;">Document Links</a></h4>
<p>More useful perhaps is a script to extract external links from <a href="https://en.wikipedia.org/wiki/Markdown" id="_gCEHmPFk" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Markdown#bodyContent">Markdown</a> files and print them to standard out: <a href="haskell/link-extractor.hs" id="_iBWDQeH6" data-link-icon="code" data-link-icon-type="svg" data-link-icon-color="#5e5086">link-extractor.hs</a></p>
<p>So now I can take <code>find . -name "*.page"</code>, pass the 100 or so Markdown files in my wiki as arguments, and add the thousand or so external links to the archiver queue (eg. <code>find . -name "*.page" -type f -print0 | xargs -0 runhaskell haskell/link-extractor.hs | filter-urls &gt;&gt; ~/.urls.txt</code>); they will eventually be archived/backed up.</p>
</section>
<section id="website-spidering" class="level4">
<h4><a href="#website-spidering" title="Link to section: ¬ß &#39;Website spidering&#39;">Website Spidering</a></h4>
<p>Sometimes a particular website is of long-term interest to one even if one has not visited <em>every</em> page on it; one could manually visit them and rely on the previous Firefox script to dump the URLs into <code>archiver</code> but this isn‚Äôt always practical or time-efficient. <code>linkchecker</code> inherently spiders the websites it is turned upon, so it‚Äôs not a surprise that it can build a <a href="https://en.wikipedia.org/wiki/Site_map" id="_6HsmGPcb" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Site_map#bodyContent">site map</a> or simply spit out all URLs on a domain; unfortunately, while <code>linkchecker</code> has the ability to output in a remarkable variety of formats, it cannot simply output a newline-delimited list of URLs, so we need to post-process the output considerably. The following is the shell one-liner I use when I want to archive an entire site (note that this is a bad command to run on a large or heavily hyper-linked site like the English Wikipedia or <a href="http://lesswrong.com" id="_MvNHJPzS">LessWrong</a>!); edit the target domain as necessary:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">linkchecker</span> <span class="at">--check-extern</span> <span class="at">-odot</span> <span class="at">--complete</span> <span class="at">-v</span> <span class="at">--ignore-url</span><span class="op">=</span>^mailto <span class="at">--no-warnings</span> http://www.longbets.org</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">fgrep</span> http</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">fgrep</span> <span class="at">-v</span> <span class="at">-e</span> <span class="st">&quot;label=&quot;</span> <span class="at">-e</span> <span class="st">&quot;-&gt;&quot;</span> <span class="at">-e</span> <span class="st">&#39;&quot; [&#39;</span> <span class="at">-e</span> <span class="st">&#39;&quot; ]&#39;</span> <span class="at">-e</span> <span class="st">&quot;/ &quot;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">&quot;s/href=</span><span class="dt">\&quot;</span><span class="st">//&quot;</span> <span class="at">-e</span> <span class="st">&quot;s/</span><span class="dt">\&quot;</span><span class="st">,//&quot;</span> <span class="at">-e</span> <span class="st">&quot;s/ //&quot;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="ex">filter-urls</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--unique</span> <span class="op">&gt;&gt;</span> ~/.urls.txt</span></code></pre></div>
<p>When <code>linkchecker</code> does not work, one alternative is to do a <code>wget --mirror</code> and extract the URLs from the filenames - list all the files and prefix with a ‚Äúhttp://‚Äù etc.</p>
</section>
</section>
</section>
</section>
<section id="reacting-to-broken-links" class="level1">
<h1><a href="#reacting-to-broken-links" title="Link to section: ¬ß &#39;Reacting to broken links&#39;">Reacting to Broken Links</a></h1>
<p><code>archiver</code> combined with a tool like <code>link-checker</code> means that there will rarely be any broken links on <code>gwern.net</code> since one can either find a live link or use the archived version. In theory, one has multiple options now:</p>
<ol start="0" type="1">
<li><p>Search for a copy on the live Web</p></li>
<li><p>link the Internet Archive copy</p></li>
<li><p>link the WebCite copy</p></li>
<li><p>link the WikiWix copy</p></li>
<li><p>use the <code>wget</code> dump</p>
<p>If it‚Äôs been turned into a full local file-based version with <code>--convert-links --page-requisites</code>, one can easily convert the dump into something like a standalone PDF suitable for public distribution. (A PDF is easier to store and link than the original directory of bits and pieces or other HTML formats like a ZIP archive of said directory.)</p>
<p>I use <a href="http://code.google.com/p/wkhtmltopdf/" id="_Ib6YoJUe" data-link-icon="alphabet" data-link-icon-type="svg" data-link-icon-color="#4285f4"><code>wkhtmltopdf</code></a> which does a good job; an example of a dead webpage with no Internet mirrors is <code>http://www.aeiveos.com/~bradbury/MatrioshkaBrains/MatrioshkaBrainsPaper.html</code> which can be found at <a href="/docs/1999-bradbury-matrioshkabrains.pdf" id="_4waPwvXJ" class="link-modified-recently" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02">1999-bradbury-matrioshkabrains.pdf</a>, or Sternberg et al‚Äôs <span class="date-range">2001<sub><span title="2001 was 25 years ago.">25ya</span></sub></span> review <a href="/docs/dnb/2001-sternberg.pdf" id="_4VJZsRYg" class="link-modified-recently" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02">‚ÄúThe Predictive Value of IQ‚Äù</a>.</p></li>
</ol>
</section>
<section id="external-links" class="level1">
<h1><a href="#external-links" title="Link to section: ¬ß &#39;External links&#39;">External Links</a></h1>
<ul>
<li><p><a href="http://www.archive-it.org/" id="_9TZ3Es1E" data-link-icon="internet-archive" data-link-icon-type="svg">Archive-It</a> -(by the Internet Archive)</p></li>
<li><p><a href="http://pinboard.in/" id="_o-6Yc-Aw">Pinboard</a></p>
<ul>
<li><p><a href="http://blog.pinboard.in/2010/11/bookmark_archives_that_don_t/" id="_TpQKV-a6">‚ÄúBookmark Archives That Don‚Äôt‚Äù</a></p></li>
</ul></li>
<li><p><a href="http://samsaffron.com/archive/2012/06/07/testing-3-million-hyperlinks-lessons-learned#comment-31366" id="_DbPVbJxi">‚ÄúTesting 3 million hyperlinks, lessons learned‚Äù</a>, Stack Exchange</p></li>
<li><p><a href="/docs/2011-muflax-backup.pdf" id="_a0wxSdq-" class="link-modified-recently" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02">‚ÄúBackup All The Things‚Äù</a>, muflax</p></li>
<li><p><a href="https://news.ycombinator.com/item?id=6504331" id="_8NBVwyQT" data-link-icon="hacker-news" data-link-icon-type="svg" data-link-icon-color="#f26522">Hacker News discussion</a></p></li>
</ul>
</section>
<section id="appendices" class="level1">
<h1><a href="#appendices" title="Link to section: ¬ß &#39;Appendices&#39;">Appendices</a></h1>
<section id="filter-urls" class="level2">
<h2><a href="#filter-urls" title="Link to section: ¬ß &#39;filter-urls&#39;"><code>filter-urls</code></a></h2>
<p>A raw dump of URLs, while certainly archivable, will typically result in a very large mirror of questionable value (is it really necessary to archive Google search queries or Wikipedia articles? usually, no) and worse, given the rate-limiting necessary to store URLs in the Internet Archive or other services, may wind up delaying the archiving of the important links &amp; risking their total loss. Disabling the remote archiving is unacceptable, so the best solution is to simply take a little time to manually blacklist various domains or URL patterns.</p>
<p>This blacklisting can be as simple as a command like <code>filter-urls | grep -v en.bwikipedia.org</code>, but can be much more elaborate. The following shell script is the skeleton of my own custom blacklist, derived from manually filtering through several years of daily browsing as well as spiders of <a href="http://lesswrong.com/lw/7kg/rationalist_sites_worth_archiving/" id="_u6Q47sjJ" title="Rationalist sites worth archiving?">dozens of websites</a> for various people &amp; purposes, demonstrating a variety of possible techniques: regexps for domains &amp; file-types &amp; query-strings, <code>sed</code>-based rewrites, fixed-string matches (both blacklists and whitelists), etc:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/sh</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># USAGE: `filter-urls` accepts on standard input a list of newline-delimited URLs or filenames,</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and emits on standard output a list of newline-delimited URLs or filenames.</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This list may be shorter and entries altered. It tries to remove all unwanted entries, where &#39;unwanted&#39;</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># is a highly idiosyncratic list of regexps and fixed-string matches developed over hundreds of thousands</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># of URLs/filenames output by my daily browsing, spidering of interesting sites, and requests</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># from other people to spider sites for them.</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># You are advised to test output to make sure it does not remove</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># URLs or filenames you want to keep. (An easy way to test what is removed is to use the `comm` utility.)</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># For performance, it does not sort or remove duplicates from output; both can be done by</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># piping `filter-urls` to `sort --unique`.</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="at">-e</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> /dev/stdin <span class="dt">\</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">&quot;s/#.*//&quot;</span> <span class="at">-e</span> <span class="st">&#39;s/&gt;$//&#39;</span> <span class="at">-e</span> <span class="st">&quot;s/&amp;sid=.*$//&quot;</span> <span class="at">-e</span> <span class="st">&quot;s/\/$//&quot;</span> <span class="at">-e</span> <span class="st">&#39;s/$/\n/&#39;</span> <span class="at">-e</span> <span class="st">&#39;s/\?sort=.*$//&#39;</span> <span class="dt">\</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">-e</span> <span class="st">&#39;s/^[ \t]*//&#39;</span> <span class="at">-e</span> <span class="st">&#39;s/utm_source.*//&#39;</span> <span class="at">-e</span> <span class="st">&#39;s/https:\/\//http:\/\//&#39;</span> <span class="at">-e</span> <span class="st">&#39;s/\?showComment=.*//&#39;</span> <span class="dt">\</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">grep</span> <span class="st">&quot;\.&quot;</span> <span class="dt">\</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">fgrep</span> <span class="at">-v</span> <span class="st">&quot;*&quot;</span> <span class="dt">\</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">egrep</span> <span class="at">-v</span> <span class="at">-e</span> <span class="st">&#39;\/\.rss$&#39;</span> <span class="at">-e</span> <span class="st">&quot;\.tw$&quot;</span> <span class="at">-e</span> <span class="st">&quot;//%20www\.&quot;</span> <span class="at">-e</span> <span class="st">&quot;/file-not-found&quot;</span> <span class="at">-e</span> <span class="st">&quot;258..\.com/$&quot;</span> <span class="dt">\</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> <span class="st">&quot;3qavdvd&quot;</span> <span class="at">-e</span> <span class="st">&quot;://avdvd&quot;</span> <span class="at">-e</span> <span class="st">&quot;\.avi&quot;</span> <span class="at">-e</span> <span class="st">&quot;\.com\.tw&quot;</span> <span class="at">-e</span> <span class="st">&quot;\.onion&quot;</span> <span class="at">-e</span> <span class="st">&quot;\?fnid\=&quot;</span> <span class="at">-e</span> <span class="st">&quot;\?replytocom=&quot;</span> <span class="dt">\</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> <span class="st">&quot;^lesswrong.com/r/discussion/comments$&quot;</span> <span class="at">-e</span> <span class="st">&quot;^lesswrong.com/user/gwern$&quot;</span> <span class="dt">\</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> <span class="st">&quot;^webcitation.org/query$&quot;</span> <span class="dt">\</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> <span class="st">&quot;ftp.*&quot;</span> <span class="at">-e</span> <span class="st">&quot;6..6\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;6..9\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;6??6\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;7..7\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;7..8\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;7..\.com&quot;</span> <span class="dt">\</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> <span class="st">&quot;78..\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;7??7\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;8..8\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;8??8\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;9..9\.com&quot;</span> <span class="at">-e</span> <span class="st">&quot;9??9\.com&quot;</span> <span class="dt">\</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">-e</span> gold.<span class="pp">*</span>sell <span class="at">-e</span> vip.<span class="pp">*</span>club <span class="dt">\</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span> <span class="fu">fgrep</span> <span class="at">-v</span> <span class="at">-e</span> <span class="st">&quot;#!&quot;</span> <span class="at">-e</span> <span class="st">&quot;.bin&quot;</span> <span class="at">-e</span> <span class="st">&quot;.mp4&quot;</span> <span class="at">-e</span> <span class="st">&quot;.swf&quot;</span> <span class="at">-e</span> <span class="st">&quot;/mediawiki/index.php?title=&quot;</span> <span class="at">-e</span> <span class="st">&quot;/search?q=cache:&quot;</span> <span class="dt">\</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>      <span class="at">-e</span> <span class="st">&quot;/wiki/Special:Block/&quot;</span> <span class="at">-e</span> <span class="st">&quot;/wiki/Special:WikiActivity&quot;</span> <span class="at">-e</span> <span class="st">&quot;Special%3ASearch&quot;</span> <span class="dt">\</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">-e</span> <span class="st">&quot;Special:Search&quot;</span> <span class="at">-e</span> <span class="st">&quot;__setdomsess?dest=&quot;</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co"># prevent URLs from piling up at the end of the file</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span></span></code></pre></div>
<p><code>filter-urls</code> can be used on one‚Äôs local archive to save space by deleting files which may be downloaded by <code>wget</code> as dependencies. For example:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">find</span> ~/www <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--unique</span> <span class="op">&gt;&gt;</span> full.txt <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">find</span> ~/www <span class="kw">|</span> <span class="ex">filter-urls</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--unique</span> <span class="op">&gt;&gt;</span> trimmed.txt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">comm</span> <span class="at">-23</span> full.txt trimmed.txt <span class="kw">|</span> <span class="fu">xargs</span> <span class="at">-d</span> <span class="st">&quot;\n&quot;</span> rm</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> full.txt trimmed.txt</span></code></pre></div>
<p>This shrunk my archive by 9GB from 65GB to 56GB, although at the cost of some archiving fidelity by removing many filetypes like CSS or JavaScript or GIF images.</p>
</section>
<section id="sort---key-compression-trick" class="level2">
<h2><a href="#sort---key-compression-trick" title="Link to section: ¬ß &#39;sort --key compression trick&#39;"><code>sort --key</code> Compression Trick</a></h2>
<p>One way to look at data compression is as a form of intelligence (see the <a href="https://en.wikipedia.org/wiki/Hutter_Prize" id="_TEp5p2t_" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Hutter_Prize#bodyContent">Hutter Prize</a> &amp; <a href="http://arxiv.org/abs/1104.5466" id="_VIUQ4EpF" data-link-icon="ùõò" data-link-icon-type="text" data-link-icon-color="#b31b1b" title="Notes on a New Philosophy of Empirical Science"><span class="cite"><span class="cite-author">Burfoot</span><span class="cite-date">2011</span></span></a>): a compression tool like <a href="https://en.wikipedia.org/wiki/Xz" id="_uYAK_lp0" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Xz#bodyContent"><code>xz</code></a> is being asked to predict what the next bit of the original file is, and the better its predictions, the less data needs to be stored to correct its mistaken predictions (‚ÄúI know how to spell ‚Äòbanana‚Äô, I just don‚Äôt know when to stop‚Äù). The smarter the program is, the better its compression will be; but on the flip side, you can also improve the compression ratio by giving it a little help and organizing the data into an equivalent form the program can understand better - for example, by using the <a href="https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform" id="_bcz5DOqc" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform#bodyContent">Burrows-Wheeler transform</a>. Or by preserving spatial locality: keeping similar data together, and not dispersing it all over. (This also explains why multimedia files barely compress: because the lossy encodings are the product of decades of work specialized to the particular domain of audio or images or video, and a general-purpose lossless compression would have to be <em>very</em> intelligent, on par with <a href="https://en.wikipedia.org/wiki/PAQ" id="_TXvOSFbd" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/PAQ#bodyContent">PAQ</a>, to beat them at their own game.) Files on one topic should be compressed together.</p>
<section id="locality" class="level3">
<h3><a href="#locality" title="Link to section: ¬ß &#39;Locality&#39;">Locality</a></h3>
<p>Spatial locality can be subtle. For example, natural language text, though not structured line-by-line as visibly as a dictionary, is still far from random and has many local correlations a compression tool might be able to pick up. If this is true, we would expect that with a sufficiently smart compressor, a text file would compress better in its natural form than if it were randomly shuffled. Is this the case, or are compression utilities are too stupid to see any different between random lines and English prose? Taking 14M of text from <code>gwern.net</code>, we can see for ourselves:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># uncompressed</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> cat <span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>/<span class="pp">*</span>.page <span class="kw">|</span>                                                 <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ex">13588814</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compressed, files in lexicographic order</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> cat <span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>/<span class="pp">*</span>.page <span class="kw">|</span>                      <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--extreme</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="ex">3626732</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># compressed, all lines sorted alphabetically</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> cat <span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>/<span class="pp">*</span>.page <span class="kw">|</span> <span class="fu">sort</span>               <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--extreme</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="ex">3743756</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># compressed, all lines randomly shuffled except for non-unique lines sorted together</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> cat <span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>/<span class="pp">*</span>.page <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--random-sort</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--extreme</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="ex">3831740</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compressed, all lines randomly shuffled</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> cat <span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>.page <span class="pp">*</span>/<span class="pp">*</span>/<span class="pp">*</span>.page <span class="kw">|</span> <span class="fu">shuf</span>               <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--extreme</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="ex">3862632</span></span></code></pre></div>
<p><!-- $ --></p>
<p>The unmolested text compresses to 3.626M, but the <em>same</em> text randomly shuffled is 3.862M! I also included an intermediate form of randomization: despite the name, the <code>--random-sort</code> option to <code>sort</code> is not actually a random shuffle but a random <em>hash</em> (this is not documented in the man page, though it is in the info page) and so any repeated non-unique lines will be sorted together (allowing for some easy duplication deletion), and so we would expect the only-partial randomization of <code>--random-sort</code> to maybe perform a bit better than the true random shuffle of <code>shuf</code>. And it does.</p>
</section>
<section id="web-archives" class="level3">
<h3><a href="#web-archives" title="Link to section: ¬ß &#39;Web archives&#39;">Web Archives</a></h3>
<p>Spatial locality also applies to our web archiving. If you are mirroring websites, or otherwise compiling a lot of directories with redundant data on a file-by-file level, there‚Äôs a cute trick to massively improve your compression ratios: don‚Äôt sort the usual lexicographic way, but sort by a subdirectory. (I learned about this trick a few years ago while messing around with archiving my home directory using <code>find</code> and <code>tar</code>.) This is one of the issues with archiving gigabytes of crawls from thousands of domains: URLs have a historical oddity where they are not consistently hierarchical. URLs were originally modeled after hierarchical <a href="https://en.wikipedia.org/wiki/Unix" id="_kS3KX02p" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Unix#bodyContent">Unix</a> filesystems; this page, for example, lives at the name <code>/home/gwern/wiki/Archiving URLs.page</code>, which follows a logical left-to-right pattern of increasing narrowness. If one lists my entire filesystem in lexicographic order, all the files in <code>/home/gwern/</code> will be consecutive, and the files in <code>wiki/</code> will be consecutive, and so on. unfortunately, the top level of URLs breaks this scheme - one does not visit <code>https://com/google/mail/?shva=1#search/l%3aunread</code>, one visits <code>https://mail.google.com/mail/?shva=1#search/l%3aunread</code>; one does not visit <code>http://net/www/gwern/Archiving%20URLs</code> but <code>http://www.gwern.net/Archiving%20URLs</code>. So if I download <code>a.google.com</code> and then later <code>z.google.com</code>, a lexicographic list of downloaded files will separate the files as much as possible (even though they are semantically probably similar). A quick example from my current WWW archive:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> ls</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="ex">typemoon.wikia.com/</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="ex">tytempletonart.wordpress.com/</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="ex">ubc-emotionlab.ca/</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="ex">ubook.info/</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="ex">ucblibrary3.berkeley.edu/</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="ex">uhaweb.hartford.edu/</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="ex">ujsportal.pacourts.us/</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="ex">ukpmc.ac.uk/</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="ex">uk.reuters.com/</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="ex">ultan.org.uk/</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span></span></code></pre></div>
<p>The directories are indeed sorted, but aside from the initial 2 letters or so, look nothing like each other: a Wikia subdomain rubs shoulders with a WordPress blog, a <code>.ca</code> domain is between a <code>.com</code>, a <code>.info</code>, and a <code>.edu</code> (with a <code>.us</code> and <code>.uk</code> thrown in for variety), and so on. Is there any way to sort these directories with a bit of parsing thrown in? For example, maybe we could reverse each line? Some web browsers store URLs reversed right-to-left to enable more efficient database operations, as do Google‚Äôs <a href="https://en.wikipedia.org/wiki/Bigtable" id="_GQ9KQKYv" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Bigtable#bodyContent">BigTable</a> systems<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> (to assist their relatively weak compression utility <a href="https://en.wikipedia.org/wiki/Snap_(software)" id="_TfrdKfOl" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Snap_(software)#bodyContent">Snappy</a>). Turns out GNU <a href="https://en.wikipedia.org/wiki/Sort_(Unix)" id="_sm28ollx" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Sort_(Unix)#bodyContent"><code>sort</code></a> already supports something similar, the <code>--key</code> &amp; <code>--field-separator</code> options; the man page is not very helpful but the <a href="https://en.wikipedia.org/wiki/Info_(Unix)" id="_LwB6xrAp" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Info_(Unix)#bodyContent">info</a> page tells us:</p>
<pre><code>&#39;-t SEPARATOR&#39;
&#39;--field-separator=SEPARATOR&#39;
     Use character SEPARATOR as the field separator when finding the
     sort keys in each line.  By default, fields are separated by the
     empty string between a non-blank character and a blank character.
     By default a blank is a space or a tab, but the &#39;LC_CTYPE&#39; locale
     can change this.

     That is, given the input line &#39; foo bar&#39;, &#39;sort&#39; breaks it into
     fields &#39; foo&#39; and &#39; bar&#39;.  The field separator is not considered
     to be part of either the field preceding or the field following,
     so with &#39;sort -t &quot; &quot;&#39; the same input line has three fields: an
     empty field, &#39;foo&#39;, and &#39;bar&#39;.  However, fields that extend to the
     end of the line, as &#39;-k 2&#39;, or fields consisting of a range, as
     &#39;-k 2,3&#39;, retain the field separators present between the
     endpoints of the range.


&#39;-k POS1[,POS2]&#39;
&#39;--key=POS1[,POS2]&#39;
     Specify a sort field that consists of the part of the line between
     POS1 and POS2 (or the end of the line, if POS2 is omitted),
     _inclusive_.

     Each POS has the form &#39;F[.C][OPTS]&#39;, where F is the number of the
     field to use, and C is the number of the first character from the
     beginning of the field.  Fields and character positions are
     numbered starting with 1; a character position of zero in POS2
     indicates the field&#39;s last character.  If &#39;.C&#39; is omitted from
     POS1, it defaults to 1 (the beginning of the field); if omitted
     from POS2, it defaults to 0 (the end of the field).  OPTS are
     ordering options, allowing individual keys to be sorted according
     to different rules; see below for details.  Keys can span multiple
     fields.

     Example:  To sort on the second field, use &#39;--key=2,2&#39; (&#39;-k 2,2&#39;).
     See below for more notes on keys and more examples.  See also the
     &#39;--debug&#39; option to help determine the part of the line being used
     in the sort.</code></pre>
<p>Hence, we can do better by ordering <code>sort</code> to break on the dots and focus on the second part of a URL, like so:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> ls <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--key</span><span class="op">=</span>2 <span class="at">--field-separator</span><span class="op">=</span><span class="st">&quot;.&quot;</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="ex">uhaweb.hartford.edu/</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="ex">adsabs.harvard.edu/</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="ex">chandra.harvard.edu/</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="ex">cmt.harvard.edu/</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="ex">dash.harvard.edu/</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="ex">gking.harvard.edu/</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="ex">isites.harvard.edu/</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span></span></code></pre></div>
<p>There‚Äôs many possible ways to sort, though. So I took my WWW archive as of 15 June <span class="date-range">2014<sub><span title="2014 was 12 years ago.">12ya</span></sub></span>, optimized all PNGs &amp; JPEGs with <code>optipng</code> &amp; <code>jpegoptim</code>, ran all the files through <code>filter-urls</code> &amp; deleted the ones which failed (this took out all of the JS files, which is fine since I don‚Äôt think those are useful for archival purposes), and was left with ~86.5GB of files. Then I tested out several ways of sorting the filenames to see what gave the best compression on my corpus.</p>
<p>First, I establish the baseline:</p>
<ol type="1">
<li><p>Size of uncompressed unsorted tarball, which eliminates filesystem overhead and tells us how much compression is really saving:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> ./ <span class="at">-type</span> f <span class="at">-print0</span> <span class="kw">|</span> <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--null</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="ex">86469734400</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="ex">1x</span></span></code></pre></div></li>
<li><p>Size of sorted tarball:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="at">-print0</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--zero-terminated</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--null</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="ex">86469734400</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="ex">1x</span></span></code></pre></div>
<p>So sorting a tarball doesn‚Äôt give any benefits. This is mostly as I expected, since <code>tar</code> is only supposed to produce a linear archive packing together all the specified files and otherwise preserve them exactly. I thought there might have been some sort of consolidation of full path-names which might yield a small space savings, but apparently not.</p></li>
</ol>
<p>Now we can begin sorting before compression. I thought of 6 approaches; in decreasing order of final archive (smaller=better):</p>
<ol type="1">
<li><p>Sort by file names, simply by reversing, sorting, unreverse (<code>foo.png ... bar.png</code> reverses to <code>gnp.oof ... gnp.rab</code>, which then sort together, and then losslessly reverse back to <code>bar.png / foo.png / ...</code>):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="kw">|</span> <span class="fu">rev</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="kw">|</span> <span class="fu">rev</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="ex">24970605748</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.2887x</span></span></code></pre></div>
<p>(Note that <code>find</code>+<code>rev</code> doesn‚Äôt correctly handle filenames with the wrong/non-UTF-8 encoding; I ultimately used brute force in the form of <a href="http://linux.die.net/man/1/detox" id="_geW1fjhQ"><code>detox</code></a> to find all the non-UTF-8 files and rename them.)</p></li>
<li><p>Compress tarball, but without any sorting (files are consumed in the order <code>find</code> produces them in the filesystem):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="at">-print0</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--null</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="ex">24268747400</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.2806x</span></span></code></pre></div></li>
<li><p>Sort by file suffixes, trying to parsing the filenames first:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="at">-printf</span> <span class="st">&#39;%f/%p\n&#39;</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--field-separator</span><span class="op">=</span><span class="st">&quot;.&quot;</span> <span class="at">--key</span><span class="op">=</span>2  <span class="kw">|</span> <span class="fu">cut</span> <span class="at">-f2-</span> <span class="at">-d</span>/ <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="ex">24097155132</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.2786x</span></span></code></pre></div></li>
<li><p>Sort normally, in lexicographic order (subdomain, domain, TLD, subdirectories &amp; files etc):</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="at">-print0</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--zero-terminated</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--null</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="ex">23967317664</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.2771x</span></span></code></pre></div></li>
<li><p>Sort by middle of domain: ~<del>{.Bash} cd ~/www/ &amp;&amp; find . -type f -print0 | sort ‚Äìzero-terminated ‚Äìkey=3 ‚Äìfield-separator=‚Äú.‚Äù |<br />
tar c ‚Äìto-stdout ‚Äìno-recursion ‚Äìnull ‚Äìfiles-from - | xz -9 ‚Äìstdout | wc ‚Äìbytes 23946061272 0.2769x</del>~</p></li>
<li><p>Sort by first subdirectory (if there‚Äôs a bunch of <code>foo.com/wp-content/*</code> &amp; <code>bar.com/wp-content/*</code> files, then the <code>/wp-content/</code> files will all sort together regardless of ‚Äúf‚Äù and ‚Äúb‚Äù being far from each other; similarly for <code>domain.com/images/</code>, <code>domain.com/css/</code> etc):</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/www/ <span class="kw">&amp;&amp;</span> <span class="fu">find</span> . <span class="at">-type</span> f <span class="at">-print0</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="at">--zero-terminated</span> <span class="at">--key</span><span class="op">=</span>3 <span class="at">--field-separator</span><span class="op">=</span><span class="st">&quot;/&quot;</span>  <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">tar</span> c <span class="at">--to-stdout</span> <span class="at">--no-recursion</span> <span class="at">--null</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--stdout</span> <span class="kw">|</span> <span class="fu">wc</span> <span class="at">--bytes</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="ex">23897682908</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.2763x</span></span></code></pre></div></li>
</ol>
<p>Surprisingly, #1, reversing filenames in order to sort on the suffixes, turns out to be even worse than not sorting at all. The improved attempt to sort on filetypes doesn‚Äôt do much better, although it at least beats the baseline of no-sorting; it may be that to get a compression win real semantic knowledge of filetypes will be needed (perhaps calling <code>file</code> on every file and sorting by the detected filetype?). The regular sort also performs surprisingly well, but my intuitions win for once and it‚Äôs beaten by my previous strategy of sorting by the middle of domains. Finally, the winner is a bit of a surprise too, a sort I only threw in out of curiosity because I noticed blogs tend to have similar site layouts.</p>
<p>In this case, the best version saved <span class="math inline">\(24268747400-23897682908=371064492\)</span> or 371MB over the unsorted version. Not as impressive as in the next use case, but enough to show this seems like a real gain</p>
</section>
<section id="separate-mirrors" class="level3">
<h3><a href="#separate-mirrors" title="Link to section: ¬ß &#39;Separate mirrors&#39;">Separate Mirrors</a></h3>
<p>Top-level domains are not the only thing we might want to sort differently on. To take my mirrors of black-market drug sites such as <a href="/Silk%20Road" id="gwern-silk%20road" class="prefetch-not link-modified-recently link-page" title="ÊöóÁΩëÂ∏ÇÂú∫‰∏éÂä†ÂØÜË¥ßÂ∏Å">Silk Road</a>: I download a site each time as a separate <code>wget</code> run in a timestamped folder. So in my Silk Road 2 folder, I have both <code>2013-12-25/</code> &amp; <code>2014-01-15/</code>. These share many similar &amp; identical files so they compress together with <code>xz</code> down from 1.8GB to 0.3GB.</p>
<p>But they <em>could</em> compress even better: the similar files may be thousands of files and hundreds of megabytes away by alphabetical or file-inode order, so even with a very large window and a top-notch compressor, it will fail to spot many long-range redundancies. In between <code>2013-12-25/default.css</code> and <code>2014-01-15/default.css</code> is going to be all sorts of files which have nothing to do with CSS, like <code>2014-01-16/items/2-grams-of-pure-vanilla-ketamine-powder-dutchdope?vendor_feedback_page=5</code> and <code>2014-01-16/items/10-generic-percocet-10-325-plus-1-30mg-morphine</code>. You see the problem.</p>
<p>Because we sort the files by ‚Äòall files starting with ‚Äú2013‚Äù‚Äô and then ‚Äòall files starting ‚Äú2014‚Äù‚Äô, we lose all proximity. If instead, we could sort by subfolder and only then by the top-level folder, then we‚Äôd have everything line up nicely. Fortunately, we already know how to do this! Reuse the sort-key trick, specify ‚Äú/‚Äù as the delimiter to parse on, and the nth field to sort on. We feed it a file list, tell it to break filenames by ‚Äú/‚Äù, and then to sort on a lower level, and if we did it right, we will indeed get output like <code>2013-12-25/default.css</code> just before <code>2014-01-15/default.css</code>, which will do wonders for our compression, and which will pay ever more dividends as we accumulate more partially-redundant mirrors.</p>
<p>Here is an example of output for my Pandora mirrors, where, due to frequent rumors of its demise triggering mirroring on my part, I have 5 full mirrors at the time of testing; and naturally, if we employ the sort-key trick (<code>find . -type f | sort --key=3 --field-separator="/"</code>), we find a lot of similar-sounding files:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a66e5238421f0422706b267b735d2df/6</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-16/profile/5a9df4f5482d55fb5a8997c270a1e22d</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5a9df4f5482d55fb5a8997c270a1e22d/1</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a9df4f5482d55fb5a8997c270a1e22d.1</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5a9df4f5482d55fb5a8997c270a1e22d/2</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a9df4f5482d55fb5a8997c270a1e22d.2</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5a9df4f5482d55fb5a8997c270a1e22d/3</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a9df4f5482d55fb5a8997c270a1e22d/4</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a9df4f5482d55fb5a8997c270a1e22d/5</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5a9df4f5482d55fb5a8997c270a1e22d/6</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5abb81db167294478a23ca110284c587</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5acc44d370e305e252dd4e2b91fda9d0/1</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5acc44d370e305e252dd4e2b91fda9d0.1</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="ex">./2013-12-25/profile/5acc44d370e305e252dd4e2b91fda9d0/2</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="ex">./2014-01-15/profile/5acc44d370e305e252dd4e2b91fda9d0.2</span></span></code></pre></div>
<p>Note the interleaving of 5 different mirrors, impossible in a normal left-to-right alphabetical sort. You can bet that these 4 files (in 15 versions) are going to compress much better than if they were separated by a few thousand other profile pages.</p>
<p>So here‚Äôs an example invocation (doing everything in pipelines to avoid disk IO):</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>find . <span class="sc">-</span>type f <span class="sc">-</span>print0 <span class="sc">|</span> sort <span class="sc">--</span>zero<span class="sc">-</span>terminated <span class="sc">--</span>key<span class="ot">=</span><span class="dv">3</span> <span class="sc">--</span>field<span class="sc">-</span>separator<span class="ot">=</span><span class="st">&quot;/&quot;</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a> <span class="sc">|</span> tar <span class="sc">--</span>no<span class="sc">-</span>recursion <span class="sc">--</span>null <span class="sc">--</span>files<span class="sc">-</span>from <span class="sc">-</span> <span class="sc">-</span>c</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a> <span class="sc">|</span> xz <span class="sc">-</span><span class="dv">9</span> <span class="sc">--</span>extreme <span class="sc">--</span>stdout</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a> <span class="sc">&gt;</span> ..<span class="sc">/</span>mirror.tar.xz</span></code></pre></div>
<p>Used on my two Silk Road 2 mirrors which together weigh <span class="date-range">1800<sub><span title="1800 was 226 years ago.">226ya</span></sub></span>M, a normal run without the <code>--key</code>/<code>--field-separator</code> options, as mentioned before, yields a 308M archive. That‚Äôs not too bad. Certainly much better than hauling around almost 2GB. However - if I switch to the sort-key trick, however, the archive is now 271M, or 37M less. Same compression algorithm, same files, same unpacked results, same speed, just 2 little obscure <code>sort</code> options‚Ä¶ and I get an archive 87% the size of the original.</p>
<p>Not impressed? Well, I did say that the advantage increases with the number of mirrors to extract redundancy from. With only 2 mirrors, the SR2 results can‚Äôt be too impressive. How about the Pandora mirrors? 5 of them gives the technique more scope to shine. And as expected, it‚Äôs even more impressive when I compare the Pandora archives: 71M vs 162M. The sort-keyed archive is 44% of the regular archive!</p>
</section>
<section id="alternatives" class="level3">
<h3><a href="#alternatives" title="Link to section: ¬ß &#39;Alternatives&#39;">Alternatives</a></h3>
<p>The sort-key trick is most useful when we can infer a lot of spatial locality just from parts of the file names, it‚Äôs not a panacea. There are other approaches:</p>
<ol type="1">
<li><p>if we have multiple temporally-ordered datasets and we don‚Äôt mind making it more difficult to access older copies, it may be simpler to store the data as a DVCS like <a href="https://en.wikipedia.org/wiki/Git" id="_s3TIMfHd" class="link-modified-recently link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Git#bodyContent" title="Git">git</a> where each dataset is a large patch</p></li>
<li><p>sort files by minimizing binary differences between them using Timm S. M√ºller‚Äôs <a href="http://neoscientists.org/~tmueller/binsort/" id="_uPjxfbRt"><code>binsort</code></a> utility</p>
<p>The default optimization setting of <code>-o15</code> underperforms the sort-key trick on both the SR2 and Pandora datasets by 5-10MB, and a higher setting like <code>-o1000</code> is best. Note that <code>binsort</code> is <span class="math inline">\(O(n^2)\)</span> in number of files, so it‚Äôs limited to sorting &lt;10,000 files. An example pipeline for compressing posts from the Silk Road forums regarding <a href="http://www.reddit.com/r/SilkRoad/comments/1yzndq/a_trip_down_memory_lane_vladimir_limetless_and/" id="_-KTPWpPC" data-link-icon="reddit" data-link-icon-type="svg" data-link-icon-color="#ff4500">a minor Ponzi scheme there</a>, since the filenames offer little guidance for a semantically-meaningful sort:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">find</span> dkn255hz262ypmii.onion/ <span class="at">-type</span> f <span class="at">-exec</span> fgrep <span class="at">-i</span> <span class="at">-l</span> vladimir  {} <span class="dt">\;</span> <span class="op">&gt;&gt;</span> ponzi.txt</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">find</span> dkn255hz262ypmii.onion/ <span class="at">-type</span> f <span class="at">-exec</span> fgrep <span class="at">-i</span> <span class="at">-l</span> Limetless {} <span class="dt">\;</span> <span class="op">&gt;&gt;</span> ponzi.txt</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> ponzi/ <span class="kw">&amp;&amp;</span> <span class="fu">cp</span> <span class="kw">`</span><span class="fu">cat</span> ponzi.txt<span class="kw">`</span> ponzi/</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="ex">~/bin/binsort/binsort</span> <span class="at">-t</span> 6 <span class="at">-o</span> 1000 ponzi/ <span class="op">&gt;</span> ponzi-list.txt</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> ponzi-list.txt <span class="kw">|</span> <span class="fu">tar</span> <span class="at">--no-recursion</span> <span class="at">--files-from</span> <span class="at">-</span> <span class="at">-c</span> <span class="kw">|</span> <span class="fu">xz</span> <span class="at">-9</span> <span class="at">--extreme</span> <span class="at">--stdout</span> <span class="op">&gt;</span> ~/srf1-ponzi.tar.xz</span></code></pre></div>
<p>(Embarrassingly, <code>binsort</code> seems to underperform on this dataset: the files are 380M uncompressed, 3.536M sort-keyed, and 3.450M sorted.)</p></li>
<li><p>if we know there are many duplicates but they are far apart by a lexicographic sort and we don‚Äôt have any good way to sort filenames and a lot of RAM, we can try out a compression tool which specifically looks for long-range redundancies throughout the entire bitstream, such as <a href="https://en.wikipedia.org/wiki/Rzip" id="_FoF8FpTR" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Rzip#bodyContent"><code>lrzip</code></a> (<a href="http://ck.kolivas.org/apps/lrzip/" id="_SO858BKz">homepage</a>/<a href="https://wiki.archlinux.org/index.php/Lrzip" id="_8ExbSfeP">Arch wiki</a>. <code>lrzip</code> is packaged in Debian and should be at least as good as <code>xz</code> since it too uses LZMA; but it is an obscure tool which is not a default install on Linux distributions like <code>xz</code> is, and this makes distributing archives to other people difficult.</p></li>
</ol>
</section>
<section id="external-links-1" class="level3">
<h3><a href="#external-links-1" title="Link to section: ¬ß &#39;External links&#39;">External Links</a></h3>
<ul>
<li><p><a href="https://stackoverflow.com/questions/357560/sorting-multiple-keys-with-unix-sort" id="_Yy5Ao0--" data-link-icon="stack-exchange" data-link-icon-type="svg" data-link-icon-color="#f48024">‚ÄúSorting multiple keys with Unix <code>sort</code>‚Äù</a></p></li>
<li><p><a href="http://simhash.googlecode.com/svn/trunk/paper/SimHashWithBib.pdf" id="_a2y8Xzme" data-link-icon="alphabet" data-link-icon-type="svg" data-link-icon-color="#4285f4" title="Sadowski &amp; Levin 2007">‚ÄúSimHash: Hash-based Similarity Detection‚Äù</a> (see also <a href="https://en.wikipedia.org/wiki/MinHash" id="_Us3kW0uo" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/MinHash#bodyContent">MinHash</a>)</p></li>
</ul>
</section>
</section>
</section>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>I use <a href="http://duplicity.nongnu.org/" id="_fJGMMinK"><code>duplicity</code></a> &amp; <a href="http://www.nongnu.org/rdiff-backup/" id="_wCl3Hh9p"><code>rdiff-backup</code></a> to backup my entire home directory to a cheap 1.5TB hard drive (bought from Newegg using <code>forre.st</code>‚Äôs <a href="http://forre.st/storage#hdd" id="_LLtN0t58">‚ÄúStorage Analysis - GB/$ for different sizes and media‚Äù</a> price-chart); a limited selection of folders are backed up to <a href="http://www.tarsnap.com/" id="_huU563py">Tarsnap</a>.</p>
<p>I used to semiannually tar up my important folders, add <a href="https://en.wikipedia.org/wiki/PAR2" id="_5vYX5Q-W" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/PAR2#bodyContent">PAR2</a> redundancy, and burn them to DVD, but that‚Äôs no longer really feasible; if I ever get a Blu-ray burner, I‚Äôll resume WORM backups. (Magnetic media doesn‚Äôt strike me as reliable over many decades, and it would ease my mind to have optical backups.)<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><a href="https://web.archive.org/web/20121108093008/http://www.wired.com/politics/security/commentary/securitymatters/2008/02/securitymatters_0221" id="__l6ZWg4V" class="link-live" data-link-icon="internet-archive" data-link-icon-type="svg" data-url-iframe="https://web.archive.org/web/20121108093008if_/http://www.wired.com/politics/security/commentary/securitymatters/2008/02/securitymatters_0221">‚ÄúWhen the Internet Is My Hard Drive, Should I Trust Third Parties?‚Äù</a>, <em>Wired</em>:</p>
<blockquote>
<p>Bits and pieces of the web disappear all the time. It‚Äôs called ‚Äòlink rot‚Äô, and we‚Äôre all used to it. A friend saved 65 links in <span class="date-range">1999<sub><span title="1999 was 27 years ago.">27ya</span></sub></span> when he planned a trip to Tuscany; only half of them still work today. In my own blog, essays and news articles and websites that I link to regularly disappear ‚Äì sometimes within a few days of my linking to them.</p>
</blockquote>
<a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></li>
<li id="fn3"><p><a href="http://scimaps.org/exhibit/docs/dellawalle.pdf" id="_DNNf8E3E" data-link-icon="pdf" data-link-icon-type="svg" data-link-icon-color="#f40f02">‚ÄúGoing, Going, Gone: Lost Internet References‚Äù</a>; abstract:</p>
<blockquote>
<p>The extent of Internet referencing and Internet reference activity in medical or scientific publications was systematically examined in more than 1000 articles published between <span class="date-range">2000<sub><span title="2000 was 26 years ago.">26ya</span></sub></span> and <span class="date-range">2003<sub><span title="2003 was 23 years ago.">23ya</span></sub></span> in the New England Journal of Medicine, The Journal of the American Medical Association, and Science. Internet references accounted for 2.6% of all references (672/25548) and in articles 27 months old, 13% of Internet references were inactive.</p>
</blockquote>
<a href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></li>
<li id="fn4"><p>By 6 January <span class="date-range">2013<sub><span title="2013 was 13 years ago.">13ya</span></sub></span>, the number has increased to ~12000 external links, ~7200 to non-Wikipedia domains.<a href="#fnref4" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn5"><p>If each link has a fixed chance of dying in each time period, such as 3%, then the total risk of death is an <a href="https://en.wikipedia.org/wiki/Exponential_distribution" id="_gahGTOcR" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Exponential_distribution#bodyContent">exponential distribution</a>; over the time period <span class="date-range" title="The date range 2011‚Äì2070 lasted 59 years.">2011<span class="subsup"><sup>‚Äì</sup><sub>59</sub></span>2070</span> the cumulative chance it will beat each of the 3% risks is 0.<span class="date-range">1658<sub><span title="1658 was 368 years ago.">368ya</span></sub></span>. So in 2070, how many of the 2200 links will have beat the odds? Each link is independent, so they are like flipping a biased coin and form a <a href="https://en.wikipedia.org/wiki/Binomial_distribution" id="_0lE6Zs0R" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Binomial_distribution#bodyContent">binomial distribution</a>. The binomial distribution, being discrete, has no easy equation, so we just ask R how many links survive at the 5th percentile/quantile (a lower bound) and how many survive at the 95th percentile (an upper bound):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>), <span class="dv">2200</span>, <span class="fl">0.97</span><span class="sc">^</span>(<span class="dv">2070-2011</span>))</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">336</span> <span class="dv">394</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># the 50% annual link rot hypothetical:</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.50</span>), <span class="dv">2200</span>, <span class="fl">0.50</span><span class="sc">^</span>(<span class="dv">2070-2011</span>))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">0</span> <span class="dv">0</span></span></code></pre></div>
<a href="#fnref5" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></li>
<li id="fn6"><p>Sh≈çtetsu; 101, ‚ÄòBuddhism related to Blossoms‚Äô; <a href="http://www.amazon.com/Unforgotten-Dreams-Steven-D-Carter/dp/0231105762/" id="_5BenqO4-" data-link-icon="amazon" data-link-icon-type="svg" data-link-icon-color="#ffce53"><em>Unforgotten Dreams: Poems by the Zen monk Sh≈çtetsu</em></a>; trans. Steven D. Carter, ISBN 0-231-10576-2<a href="#fnref6" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn7"><p>Which I suspect is only accidentally ‚Äògeneral‚Äô and would shut down access if there were some other way to ensure that Wikipedia external links still got archived.<a href="#fnref7" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn8"><p>Since Pinboard is a bookmarking service more than an archive site, I asked whether treating it as such would be acceptable and Maciej said ‚ÄúYour current archive size, growing at 20 GB a year, should not be a problem. I‚Äôll put you on the heavy-duty server where my own stuff lives.‚Äù<a href="#fnref8" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn9"><p>Google Cache is generally recommended only as a last <a href="https://en.wikipedia.org/wiki/Ditch_(fortification)" id="_a7dmOD1r" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Ditch_(fortification)#bodyContent">ditch</a> resort because pages expire quickly from it. Personally, I‚Äôm convinced that Google would never just delete colossal amounts of Internet data - this is Google, after all, the epitome of storing unthinkable amounts of data - and that Google Cache merely ceases to make public its copies. And to request a Google spider visit, one has to solve a CAPTCHA - so that‚Äôs not a scalable solution.<a href="#fnref9" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn10"><p>Which would not be publicly accessible or submittable; I know they exist, but because they hide themselves, I know only from random comments online eg. <a href="https://news.ycombinator.com/item?id=2880427" id="_uNzlu5wY" data-link-icon="hacker-news" data-link-icon-type="svg" data-link-icon-color="#f26522">‚Äúyears ago a friend of mine who I‚Äôd lost contact with caught up with me and told me he found a cached copy of a website I‚Äôd taken down in his employer‚Äôs equivalent to the Wayback Machine. His employer was a branch of the federal government.‚Äù</a>.<a href="#fnref10" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn11"><p><a href="http://hackage.haskell.org/package/archiver-0.1" id="_HnvJ8R2m" data-link-icon="ùõå" data-link-icon-type="text" data-link-icon-color="#5e5086">Version 0.1</a> of my <code>archiver</code> daemon didn‚Äôt simply read the file until it was empty and exit, but actually watched it for modifications with <a href="https://en.wikipedia.org/wiki/Inotify" id="_H3WujJEZ" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Inotify#bodyContent">inotify</a>. I removed this functionality when I realized that the required WebCite choking (just one URL every ~25 seconds) meant that <code>archiver</code> would <em>never</em> finish any reasonable workload.<a href="#fnref11" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn12"><p>Much easier than it was in the past; <a href="https://en.wikipedia.org/wiki/Jamie_Zawinski" id="_7IuI4j9v" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/Jamie_Zawinski#bodyContent">Jamie Zawinski</a> records his travails with the <em>previous</em> Mozilla history format in the aptly-named <a href="http://www.jwz.org/blog/2004/03/when-the-database-worms-eat-into-your-brain/" id="_h7gmaUWL">‚Äúwhen the database worms eat into your brain‚Äù</a>.<a href="#fnref12" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn13"><p>An older <a href="https://code.google.com/speed/articles/web-metrics.html" id="_qj5zElKW" data-link-icon="alphabet" data-link-icon-type="svg" data-link-icon-color="#4285f4">2010 Google article</a> put the average at 320kb, but that was an average over the entire Web, including all the old content.<a href="#fnref13" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn14"><p>Already one runs old games like the classic <a href="https://en.wikipedia.org/wiki/LucasArts_adventure_games" id="_By7rGpXu" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/LucasArts_adventure_games#bodyContent">LucasArts adventure games</a> in emulators of the DOS operating system like <a href="https://en.wikipedia.org/wiki/DOSBox" id="_bvf4Jhbh" class="link-live" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-iframe="https://en.m.wikipedia.org/wiki/DOSBox#bodyContent">DOSBox</a>; but those emulators will not always be maintained. Who will emulate the emulators? Presumably in 2050, one will instead emulate some ancient but compatible OS - Windows 7 or Debian 6.0, perhaps - and inside <em>that</em> run DOSBox (to run the DOS which can run the game).<a href="#fnref14" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn15"><p><a href="http://research.google.com/archive/bigtable-osdi06.pdf" id="_ogoalr87" data-link-icon="alphabet" data-link-icon-type="svg" data-link-icon-color="#4285f4">‚ÄúBigTable: A Distributed Storage System for Structured Data‚Äù</a>, <span class="cite"><span class="cite-author-plural" title="et al">Chang</span><span class="cite-joiner"> et al </span><span class="cite-date">2006</span></span>:</p>
<blockquote>
<p>BigTable maintains data in lexicographic order by row key. The row range for a table is dynamically partitioned. Each row range is called a <em>tablet</em>, which is the unit of distribution and load balancing. As a result, reads of short row ranges are efficient and typically require communication with only a small number of machines. Clients can exploit this property by selecting their row keys so that they get good locality for their data accesses. For example, in Webtable, pages in the same domain are grouped together into contiguous rows by reversing the hostname components of the URLs. For example, we store data for <code>maps.google.com/index.html</code> under the key <code>com.google.maps/index.html</code>. Storing pages from the same domain near each other makes some host and domain analyses more efficient.</p>
</blockquote>
<a href="#fnref15" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></li>
</ol>
</aside>

      
      <noscript><div id="noscript-warning-footer" class="admonition error" title="Warning to NoScript Users"><div class="admonition-title"><p>[<strong>Error</strong>: JavaScript disabled.]</p></div> <p>[Backlinks, similar links, and the bibliography require JS enabled to load.]</p></div></noscript>
      
      
      
      
      </div> <!-- NOTE: unmatched, because it closes the opening div from the hakyll.hs $body$ Pandoc template -->

    </article>

    
    <!-- SSI: Footer -->
    <!-- FOOTER-BEGIN-->
    <!-- Footer (no SSI): injected by Hakyll from static/include/footer.html -->
        <nav id="navigation">
      <svg id="navigation-left"><use href="/static/img/ornament/sequential-nav-icons-arabesque.svg#direction" /></svg>
      <a id="navigation-center" class="link-page-not" title="Return to top of current page" href="#top"
        ><svg><use href="/static/img/ornament/sequential-nav-icons-arabesque.svg#center" /></svg></a>
      <svg id="navigation-right"><use href="/static/img/ornament/sequential-nav-icons-arabesque.svg#direction" /></svg>
    </nav>
    <div class="markdownBody" id="footer">
      <p id="footer-anonymous-feedback">
        <a href="https://docs.google.com/forms/d/e/1FAIpQLSd7uqL7B_l1HFIfXc8D_nZyumaOv58msK7jhl4XzQjWODWKdA/viewform" title="Google Docs web form for submitting anonymized feedback to Gwern Branwen">[&hairsp;Send Anonymous Feedback&hairsp;]</a>
      </p>
      <div id="x-of-the-day" class="dark-mode-invert">
        <p><a id="qotd" class="include include-spinner-not" href="/metadata/today-quote.html">[Quote Of The Day]</a></p>
        <p><a id="sotd" class="include include-spinner-not" href="/metadata/today-site.html">[Site Of The Day]</a></p>
        <p><a id="atod" class="include include-spinner-not" href="/metadata/today-annotation.html">[Annotation Of The Day]</a></p>
      </div>
      <p><a id="psa-adblock" class="include adsense include-spinner-not" href="/metadata/psa-adblock.html">[adblock public service announcement]</a></p>
    </div>

    <!-- FOOTER-END -->
    
    <div id="footer-decoration-container"> <!-- Mandatory element for layout -->
      <a rel="home me contents" title="Gwern.net homepage" class="footer-logo dark-mode-invert" href="/index">‚Äã</a>
    </div>

  </main>

  <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-18912926-1" onload="GW.googleAnalyticsLoaded = true;"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-18912926-1');
  </script>
  
  
</body>
</html>
