---
title: 警报数据的时间趋势
description: Google Alerts 每年返回的结果是否在减少？一项统计调查
created: 1 July 2013
tags: statistics
status: finished
belief: likely
...

> 过去几年 Google Alerts 发送的结果是否在减少？是的。针对关于其即将消亡的传言，我调查了我个人 Google Alerts 通知在 2007-2013 年间的结果数量，发现在查看[2011年中期](#it-was-mid-2011)的转变之前没有整体下降趋势，而在该时间点之后结果数量急剧下降。我对[原因](#panda)和对 Alerts 未来的[影响](#conclusion)进行了推测。

在研究我的 [Google shutdowns]() 文章（关于 Google 产品在被关闭之前能存活多久，灵感来自 Reader 的关闭）时，我发现了关于 [Google Alerts](!Wikipedia) 服务的一些猜测。Google Alerts 是一项代替你运行搜索查询并通过电子邮件通知你任何新的匹配网页的服务（对于跟踪话题非常有用，也是最古老的 Google 服务之一），据报道它在 2012 年[出现了](http://searchengineland.com/google-alerts-arent-working-148642 "Dear Google Alerts: Why Aren't You Working?")[严重的](http://searchengineland.com/google-alerts-still-broken-152444 "Google Alerts: Still Broken")[故障](http://thefinancialbrand.com/28346/google-alerts-broken/ "An Open Letter to Google: Google Alerts Broken, Now Useless To Financial Marketers")。当我看到这些信息时，我回忆起自己的警报确实似乎不像以前那样有用了，但我无法确定这是 Alerts 本身的问题还是我的特定关键词只是没有过去那么活跃。Google 对此话题的官方评论极为有限[^official-reply]。

[^official-reply]: ["What's Wrong With Google Alerts? The small but useful service seems to be dying. One researcher uses empirical research to answer the questions that Google won't."](http://www.buzzfeed.com/justinesharrock/whats-wrong-with-google-alerts)，发表于 _BuzzFeed_：

    > Google has refused to shed light on the decline. Today, a Google spokesperson told BuzzFeed, "we're always working to improve our products - we'll continue making updates to Google Alerts to make it more useful for people." In other words, a polite non-answer.

Alerts 的消亡对我来说将是一个严重的问题，因为我自 2007 年 1 月 28 日以来（2347 天）一直大量使用 Alerts，目前有 23 个活跃的 Alerts（过去还有更多）——在我总共 501,662 封电子邮件中，有 3,815 封是 Alert 邮件——而且似乎没有任何可用的替代方案^[我见过一些替代服务，如 [Yahoo! Search Alerts](http://www.ghacks.net/2013/06/29/yahoo-search-alerts-a-google-alerts-alternative/)、[talkwalker](http://talkwalker.com/en) 和 [Mention](https://en.mention.net/)，但我没有使用过它们；后两者在[与 Google Alerts 的对比中](http://moz.com/ugc/google-alerts-vs-mention-vs-talkwalker "Google Alerts VS Mention VS Talkwalker")表现不错。]。令人担忧的是，Alerts 的 RSS 订阅源在 [2013 年 7 月](http://googlesystem.blogspot.com/2013/07/google-alerts-drops-rss-feeds.html "Google Alerts Drops RSS Feeds")至 [2013 年 9 月](http://thenextweb.com/google/2013/09/11/google-alerts-regains-rss-delivery-option-it-lost-after-google-readers-demise/ "Google Alerts regains RSS delivery option it lost after Google Reader's demise")期间无法使用。

事实上，生存模型表明 Alerts 有很大机会长期存活，我暂时放下了这个问题，直到我想起，既然我使用 Alerts 这么多年并且有这么多邮件，我可以轻松地凭经验检验这些说法——Alerts *真的*突然停止返回大量结果了吗？这是一个简单明了的问题：从每封 Alerts 邮件中提取主题/日期/链接数量，按独立的警报分层，然后对时间进行回归分析。所以我就这样做了。

# 数据

作为备份程序的一部分，我每天使用 [`getmail4`](http://pyropus.ca/software/getmail/) 将 Gmail 邮件抓取到一个 [maildir](!Wikipedia) 中。Alerts 使用不变的主题行，例如 `Subject: Google Alert - "Frank Herbert" -mason`，因此很容易找到所有的 Alerts 邮件并将它们分离出来。

~~~{.Bash}
~/mail/
$ find ~/mail/ -type f -exec fgrep -l {} 'Google Alert -' \;
/home/gwern/mail/new/1282125775.M532208P12203Q683Rb91205f53b0fec0d.craft
/home/gwern/mail/new/1282125789.M55800P12266Q737Rd98db4aa1e58e9ed.craft
...
$ find ~/mail/ -type f -exec fgrep -l 'Google Alert -' {} \; > alerts.txt
$ mkdir 2013-09-25-gwern-googlealertsemails/
$ mv `cat alerts.txt` 2013-09-25-gwern-googlealertsemails/
~~~

<!-- find 2013-09-25-gwern-googlealertsemails/ -type f -exec grep -l aaktgeb {} \; | xargs rm -->

我删除了一些私人警报的邮件；剩余的 72M 邮件可在 [`2013-09-25-gwern-googlealertsemails.tar.xz`](/docs/2013-09-25-gwern-googlealertsemails.tar.xz) 获取。然后通过循环和临时 Shell 脚本提取主题行、日期以及每封邮件中 "http://" 出现的次数：

~~~{.Bash}
cd 2013-09-25-gwern-googlealertsemails/

echo "Search,Date,Links" >> alerts.csv # 设置标题行
for EMAIL in *.craft *.elan; do

    SUBJECT="`egrep '^Subject: Google Alert - ' $EMAIL  | sed -e 's/Subject: Google Alert - //'`"
    DATE="`egrep '^Date: ' $EMAIL | cut -d ' ' -f 3-5 | sed -e 's/<b>..*/ /'`"
    COUNT="`fgrep --no-filename --count 'http://' $EMAIL`"

    echo $SUBJECT,$DATE,$COUNT >> alerts.csv
done
~~~

脚本并不完美，在将其读入 R 并格式化为干净的 CSV 之前，我不得不删除几行错误数据：

~~~{.R}
alerts <- read.csv("alerts.csv", quote=c(), colClasses=c("character","character","integer"))
alerts$Date <- as.Date(alerts$Date, format="%d %b %Y")
write.csv(alerts, file="2013-09-25-gwern-googlealerts.csv", row.names=FALSE)
~~~

# 分析
## 描述性统计

~~~{.R}
alerts <- read.csv("http://www.gwern.net/docs/2013-09-25-gwern-googlealerts.csv",
                   colClasses=c("factor","Date","integer"))
summary(alerts)
                     Search          Date                Links
 wikipedia              : 255   Min.   :2007-01-28   Min.   :  0.0
 Neon Genesis Evangelion: 247   1st Qu.:2008-12-29   1st Qu.: 10.0
 "Gene Wolfe"           : 246   Median :2011-02-07   Median : 22.0
 "Nick Bostrom"         : 224   Mean   :2010-10-06   Mean   : 37.9
 modafinil              : 186   3rd Qu.:2012-06-15   3rd Qu.: 44.0
 "Frank Herbert" -mason : 184   Max.   :2013-09-25   Max.   :563.0
 (Other)                :2585

# 数量如此之多是因为我已经删除了许多不再感兴趣的话题，
# 并且精炼了其他警报的搜索条件
length(unique(alerts$Search))
[1] 68

plot(Links ~ Date, data=alerts)
~~~

![每封邮件中的链接数，按时间绘制](/images/google/alerts/linksperemail.png)

我注意到的第一件事是，每封邮件的链接数似乎随时间增加，在 2010 年中期出现一个峰值。第二个观察是邮件之间的差异相当大——虽然大多数在 0 附近，但有些高达 300。第三个是早期有一个奇怪的异常，邮件被记录为有 0 个链接；查看这些邮件后发现，它们是以 [base64](!Wikipedia) 编码的，原因不明，之后所有邮件都采用了更合理的 HTML/文本格式。这是 Google 一次失败的实验吗？我不得而知。最高数字是 563，并不算很大；因此尽管数据偏斜，我没有对 `Links` 进行对数变换。

## 线性模型

数据的尖锐波动促使我通过将邮件按月分桶来调整发送频率等方面的变异，并叠加一个线性回归：

~~~
library(lubridate)
alerts$Date <- floor_date(alerts$Date, "month")
alerts <- aggregate(Links ~ Search + Date, alerts, "sum")

# 一个简单的线性模型表明每月有微小的增长，但指出存在大量未解释的变异
lm <- lm(Links ~ Date, data=alerts); summary(lm)
...
Residuals:
   Min     1Q Median     3Q    Max
-175.8 -110.0  -60.5   43.3  992.6

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept) -4.13e+02   1.10e+02   -3.76  0.00018
Date         3.73e-02   7.38e-03    5.06  4.9e-07

Residual standard error: 175 on 1046 degrees of freedom
Multiple R-squared:  0.0239,    Adjusted R-squared:  0.023
F-statistic: 25.6 on 1 and 1046 DF,  p-value: 4.89e-07

plot(Links ~ Date, data=alerts)
abline(lm)
~~~

![每个搜索的总链接数，按月统计](/images/google/alerts/linkspermonth.png)

与原始图没有太大差异：仍然是一个总体上升趋势。这个回归有一个基本问题：这种增长是反映了我*订阅的警报数量*的增加、对每个警报的调整使其返回更多结果（从旧警报转换到*新*警报），还是每个*独立*警报的链接数量增加？只有最后一种说法是我们感兴趣的，但这些或其他现象中的任何一个都可能产生增长。

### 每个警报单独分析

我们可以尝试分别处理每个警报并对其进行线性回归，然后与对所有数据不加区分的线性模型进行比较：

~~~{.R}
library(ggplot2)
qplot(Date, Links, color=Search, data=alerts) +
    stat_smooth(method="lm", se=FALSE, fullrange=TRUE, size=0.2) +
    geom_abline(aes(intercept=lm$coefficients[1], slope=lm$coefficients[2], color=c()), size=1) +
    ylim(0,1130) +
    theme(legend.position = "none")
~~~

![按警报拆分数据，分别进行回归](/images/google/alerts/monthlylinks-individuallinearregression.png)

结果是混乱的。各个警报的趋势指向不同的方向。对所有警报一起进行回归会混淆问题，而对单个警报进行回归则无法产生一致的结论。我们需要一种折中的方法，既尊重不同警报具有不同的行为模式，又能得出有意义的整体结论。

## 多层次模型

我们想要的是查看每个独立警报，估计其随时间的增减趋势，并可能将所有斜率汇总为一个总体斜率。数据具有层次结构：Google 的整体斜率影响每个警报的斜率，而每个警报的斜率又影响该斜率周围数据点的分布。

我们可以使用[多层次模型](!Wikipedia)来实现这一点，使用 [`lme4`](http://cran.r-project.org/web/packages/lme4/index.html)。

我们将从拟合和比较两个模型开始：

1. 每个警报之间只有截距不同，但所有警报以相同的速率增加或减少
2. 每个警报之间截距不同，且警报在增长或衰减方面也有差异

~~~{.R}
library(lme4)
mlm1 <- lmer(Links ~ Date + (1|Search), alerts); mlm1

Random effects:
 Groups   Name        Variance Std.Dev.
 Search   (Intercept) 28943    170
 Residual             12395    111
Number of obs: 1048, groups: Search, 68

Fixed effects:
             Estimate Std. Error t value
(Intercept) 427.93512  139.76994    3.06
Date         -0.01984    0.00928   -2.14

Correlation of Fixed Effects:
     (Intr)
Date -0.988

mlm2 <- lmer(Links ~ Date + (1+Date|Search), alerts); mlm2

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Search   (Intercept) 6.40e+06 2529.718
          Date        2.78e-02    0.167 -0.998
 Residual             8.36e+03   91.446
Number of obs: 1048, groups: Search, 68

Fixed effects:
            Estimate Std. Error t value
(Intercept) 295.5469   420.0588    0.70
Date         -0.0090     0.0278   -0.32

Correlation of Fixed Effects:
     (Intr)
Date -0.998

# 比较模型：模型 2 是否比模型 1 更好？
anova(mlm1, mlm2)

mlm1: Links ~ Date + (1 | Search)
mlm2: Links ~ Date + (1 + Date | Search)
     Df   AIC   BIC logLik deviance Chisq Chi Df Pr(>Chisq)
mlm1  4 13070 13089  -6531    13062
mlm2  6 12771 12801  -6379    12759   303      2     <2e-16

~~~

模型 2 在简洁性/拟合度两个标准上都更好，所以我们将更仔细地查看它：

~~~{.R}
coef(mlm2)
$Search
                                                               (Intercept)      Date
                                                                    763.48 -0.046763
adult iodine supplementation (IQ OR intelligence OR cognitive)      718.80 -0.043157
AMD pacifica virtualization                                        -836.63  0.062123
(anime OR manga) (half-Japanese OR hafu OR half-American)           956.52 -0.059438
caloric restriction                                               -2023.10  0.153667
"Death Note" (script OR live-action OR Parlapanides)                866.63 -0.051314
"dual n-back"                                                      4212.59 -0.266879
dual n-back                                                        1213.85 -0.073265
electric sheep screensaver                                         -745.78  0.055937
"Frank Herbert"                                                     -93.28  0.013636
"Frank Herbert" -mason                                            10815.19 -0.676188
freenet project                                                   -1154.14  0.087199
"Gene Wolfe"                                                        496.01 -0.026575
Gene Wolfe                                                         1178.36 -0.072681
...
wikileaks                                                         -3080.74  0.227583
WikiLeaks                                                          -388.34  0.031441
wikipedia                                                         -1668.94  0.133976
Xen                                                                 390.01 -0.017209
~~~

Date 的单位是每月链接数，所以当 Xen 的斜率为 -0.02 时，意味着每年减少一个链接。

~~~{.R}
max(abs(coef(mlm2)$Search$Date))
[1] 0.6762
~~~

这个最大值来自 `"Frank Herbert" -mason` 搜索，可能反映了该搜索相对较新，或者我添加到原始 `"Frank Herbert"` 搜索中的过滤条件的有效性。总体而言，斜率非常相似，正斜率和负斜率的数量似乎相当，第二个模型中的总体汇总斜率是一个微小的负斜率（-0.01）；但在毛虫图中，大多数搜索的斜率的置信区间不包含零：

![`qqmath(ranef(mlm2, postVar=TRUE))`](/images/google/alerts/mlm2-slopes.png)

这告诉我，正如最初的说法所声称的那样，每个警报内部并没有发生大的时间变化，但似乎确实有一些情况在发生。当我们绘制总体回归和每个警报的回归时，我们看到：

~~~{.R}
fixParam <- fixef(mlm2)
ranParam <- ranef(mlm2)$Search
params   <- cbind(ranParam[1]+fixParam[1], ranParam[2]+fixParam[2])
p <- qplot(Date, Links, color=Search, data=alerts)
p +
  geom_abline(aes(intercept=`(Intercept)`, slope=Date, color=rownames(params)), data=params, size=0.2) +
  geom_abline(aes(intercept=fixef(mlm2)[1], slope=fixef(mlm2)[2], color=c()), size=1) +
  ylim(0,1130) +
  theme(legend.position = "none")
~~~

![多层次回归，总体和个体拟合](/images/google/alerts/monthlylinks-individualmlm.png)

这显然比分别对每个警报进行回归更有意义，因为我们避免了在只有少量邮件可用时出现疯狂陡峭的斜率——这些回归被收缩到了总体回归方向。我们也没有发现警报总体上存在任何大的或具有统计显著性的时间变化的证据：一些警报确实随时间增加，但一些也在随时间减少，只有一个微小的下降，我们可能将其归咎于 Google 内部问题。

<!--
### 稳健性

我们观察到的轻微负总体相关性有多可靠？我们可以通过从推断模型中随机生成数据来进行后验检查，看看总体 `Date` 固定效应从正到负变化的频率：

~~~{.R}
library(arm)
mlm2.sim <- sim(mlm2,  n.sims = 100000)
fixef.mlm2.sim <- fixef(mlm2.sim)
quantile(fixef.mlm2.sim[,2], probs = c(0, 0.025, 0.975, 1))
      0%     2.5%    97.5%     100%
-0.12879 -0.04986  0.06343  0.12596

hist(fixef.mlm2.sim[,2], main="Change in hits per month, 100k simulations", xlab="Coefficient")
~~~

![100k 次模拟运行中估计的斜率分布](/images/google/alerts/mlm2-simulation.png)
-->

## 那下降呢？

完成以上所有分析后，我以为已经结束了，直到我想起最初的博主抱怨的不是随时间的*稳定*恶化，而是从 2012 年某个时候开始的突然恶化。当我做一个二元分割并比较 2010/2011 与 2012/2013 时会发生什么？

~~~{.R}
alertsRecent <- alerts[year(alerts$Date)>=2010,]
alertsRecent$Recent <- year(alertsRecent$Date) >= 2012
wilcox.test(Links ~ Recent, conf.int=TRUE, data=alertsRecent)

    Wilcoxon rank sum test with continuity correction

data:  Links by Recent
W = 71113, p-value = 6.999e-10
alternative hypothesis: true location shift is not equal to 0
95% confidence interval:
 34 75
sample estimates:
difference in location
                    53
~~~

我避免使用基于正态性的检验如 [`t.test`](!Wikipedia "Student's t-test")，而是使用了 [Wilcoxon 检验](!Wikipedia "Mann-Whitney U")，因为没有理由期望每月链接数遵循正态分布。不管细节如何，两个时期之间存在很大差异：219 对 140 个链接！36% 的下降无疑是一个严重的衰退，而且不能被归因为我的 Alerts 设置（我始终使用"所有结果"而不是"仅最佳结果"），也不能——正如我们接下来将看到的——归因为激发多层次模型使用的那些混淆因素：

~~~{.R}
R> alerts$Recent <- year(alerts$Date) >= 2012
R> mlm3 <- lmer(Links ~ Date + Recent + (1+Date|Search), alerts); mlm3

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Search   (Intercept) 9.22e+03 9.60e+01
          Date        9.52e-05 9.75e-03 -0.164
 Residual             1.18e+04 1.09e+02
Number of obs: 1048, groups: Search, 68

Fixed effects:
             Estimate Std. Error t value
(Intercept) -440.1540   175.3630   -2.51
Date           0.0413     0.0121    3.42
RecentTRUE  -102.2273    13.3224   -7.67

Correlation of Fixed Effects:
           (Intr) Date
Date       -0.993
RecentTRUE  0.630 -0.647

R> anova(mlm1, mlm2, mlm3)
Models:
mlm1: Links ~ Date + (1 | Search)
mlm2: Links ~ Date + (1 + Date | Search)
mlm3: Links ~ Date + Recent + (1 + Date | Search)
     Df   AIC   BIC logLik deviance Chisq Chi Df Pr(>Chisq)
mlm1  4 13070 13089  -6531    13062
mlm2  6 12771 12801  -6379    12759   303      2     <2e-16
mlm3  7 13015 13050  -6500    13001     0      1          1
~~~

### 转折点在 2011 年中期

将 2012 年之前视为不同时期的新模型具有更好的拟合度。我们能做得更好吗？[`changepoint`](http://cran.r-project.org/web/packages/changepoint/index.html) 包将 2011 年 5 月/6 月指认为罪魁祸首，并给出了更大的均值差异（254 对 147）：

~~~{.R}
library(changepoint)
plot(cpt.meanvar(alertsRecent$Links), ylab="Links")
~~~

![2010-2013 年的链接数，显示 2011 年 5 月/6 月的体制转变](/images/google/alerts/changepoint.png)

使用这个新的变化点，检验更加显著：

~~~{.R}
alertsRecent <- alerts[year(alerts$Date)>=2010,]
alertsRecent$Recent <- alertsRecent$Date > "2011-05-01"
wilcox.test(Links ~ Recent, conf.int=TRUE, data=alertsRecent)

    Wilcoxon rank sum test with continuity correction

data:  Links by Recent
W = 63480, p-value = 4.61e-12
alternative hypothesis: true location shift is not equal to 0
95% confidence interval:
  62 112
sample estimates:
difference in location
                    87
~~~

拟合度也有了很大改善：

~~~{.R}
R> alerts$Recent <- alerts$Date > "2011-05-01"
R> mlm4 <- lmer(Links ~ Date + Recent + (1+Date|Search), alerts); mlm4

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Search   (Intercept) 8.64e+03 9.30e+01
          Date        9.28e-05 9.63e-03 -0.172
 Residual             1.11e+04 1.05e+02
Number of obs: 1048, groups: Search, 68

Fixed effects:
             Estimate Std. Error t value
(Intercept) -1.11e+03   1.87e+02   -5.91
Date         8.86e-02   1.30e-02    6.83
RecentTRUE  -1.65e+02   1.44e+01  -11.43

Correlation of Fixed Effects:
           (Intr) Date
Date       -0.994
RecentTRUE  0.709 -0.725

R> anova(mlm1, mlm2, mlm3, mlm4)
     Df   AIC   BIC logLik deviance Chisq Chi Df Pr(>Chisq)
mlm1  4 13070 13089  -6531    13062
mlm2  6 12771 12801  -6379    12759 302.7      2     <2e-16
mlm3  7 13015 13050  -6500    13001   0.0      1          1
mlm4  7 12948 12983  -6467    12934  66.8      0     <2e-16

~~~

#### 稳健性

<!--
鉴于上述结论，后验模拟从未给出 `Recent` 的估计值接近零也就不足为奇了：

~~~{.R}
mlm4.sim <- sim(mlm4,  n.sims = 100000)
fixef.mlm4.sim <- fixef(mlm4.sim)
quantile(fixef.mlm4.sim[,3], probs = c(0, 0.025, 0.975, 1))
     0%    2.5%   97.5%    100%
-186.74 -152.69 -101.37  -69.05
~~~

后验检查结果良好，所以我从另一个方向进行检验：
-->

使用[自助法](!Wikipedia "Bootstrapping (statistics)")，这种下降是否对数据的不同样本具有稳健性？答案是肯定的，而且 Wilcoxon 检验之前给出的置信区间其实相当不错：

~~~{.R}
library(boot)
recentEstimate <- function(dt, indices) {
  d <- dt[indices,] # 允许 boot 选择子样本
  mlm4 <- lmer(Links ~ Date + Recent + (1+Date|Search), d)
  return(fixef(mlm4)[3])
}
bs <- boot(data=alerts, statistic=recentEstimate, R=10000, parallel="multicore", ncpus=4); bs
...
Bootstrap Statistics :
    original  bias    std. error
t1*   -164.8   34.06       17.44

boot.ci(bs)
...
Intervals :
Level      Normal              Basic
95%   (-233.0, -164.7 )   (-228.2, -156.7 )

Level     Percentile            BCa
95%   (-172.9, -101.4 )   (-211.8, -156.7 )
~~~

置信区间（-159,-95）在此背景下既具有统计显著性，也是一个不容忽视的效应大小。看来这个 2011 年中期的下降是真实存在的。我惊讶地发现在我的 Alerts 数量中有如此精确、局部化的下降。我确实预期会发现一个下降，但我预期它是一个逐渐的过程——随着 Google 的搜索算法逐步排除越来越多的链接。我没想到能够做出这样的陈述："在这个月份，结果下降了超过三分之一。"

### 是 Panda 算法吗？

我不知道 2011 年 5 月/6 月有任何关于 Google Alerts 的变更公告，电子邮件也无法直接告诉我们发生了什么。但我可以进行推测。

有一个嫌疑犯让我想到了 2011 年初可能发生了什么变化，从而导致了汇总链接数量的下降（这种下降在 2011 年 6 月积累到了统计显著性水平）：对网页排名产生广泛影响的变更——[Google Panda](!Wikipedia)。它影响了许多网站和搜索，存在磨合问题，据报道促进了社交网络网站的排名（而我在自己的警报中很少看到这类网站），并于 2011 年 4 月在全球推出——恰好可以在 5 月/6 月触发变化（并在 [2011 年持续进行变更](http://moz.com/google-algorithm-change#2011 "Google Algorithm Change History")）。

（我们可能永远不会知道真正的原因：Google 在其许多内部技术决策和变更方面是出了名的不善于沟通。）

# 结论

那么这一切意味着什么？

总体线性回归最终未能回答这个问题，但它们仍然具有教育意义，展示了不同警报之间的巨大多样性以及理解我们到底在问什么问题的复杂性；警报之间的变异性和差异提醒我们不要被随机性所欺骗，要尝试寻找大效应和全局图景——如果有人说他们的警报似乎有所减少，他们可能是被选择性记忆所欺骗了，但当他们说他们的警报从每封邮件 20 个链接降到了 3 个时，我们就应该避免不假思索的怀疑，更仔细地观察。

当我们直接调查这一说法时，我们*并没有完全*找到所声称的情况：在博主们声称的 2012 年并没有变化点——他们似乎比我自己的警报中发生变化的时间晚了半年。这是怎么回事？很难说。Google 有时会在很长一段时间内向用户推出变更，因此也许我早期就受到了一些大幅减少链接的变更的影响。或者也许人们只是花了一些时间才确信链接减少了（在这种情况下，我对他们的评价过低了）。又或者是独立的 SEO 相关变更在我的搜索之后影响了他们的搜索。

Alerts 是否"坏了"？嗯，它确实受到了明显的打击：发现的链接数量下降了，而我自己的印象是返回的链接质量并没有好到能弥补其稀缺性。而且问题已经持续了 2 年却没有任何明显改善，这肯定不是好事。

但仔细观察后，这次打击似乎是一次性的，如果我关于 Panda 的推测是正确的，它并不反映 Google 的忽视或轻蔑，而只是更重要的因素——Search 保持高质量始终是比 Alerts 更高的优先级，因为 Search 是摇尾巴的那条狗。我的生存模型可能最终会笑到最后，Alerts 可能会比它更著名的同类产品活得更久。

我想这取决于你如何看待这杯水：如果看到半满，那这就是好消息，因为这意味着 Alerts 的状况没有看起来那么糟糕，可能不会很快跟随 Reader 进入天上的大回收站；如果看到半空，那这就是 Google 不与用户沟通、单方面和隐蔽地进行更改、为了更有利可图的服务而降低一个服务质量的又一个例子，以及用户在其技术霸权面前是多么无助（还有谁能做得这么好——在互联网上爬取与关键词匹配的新内容？）。

# 参见

- [同人小说评论者生存曲线](hpmor "生存分析未发现评论者寿命存在重大异常，但发现从较晚章节开始评论的评论者的死亡率似乎有所增加")
- [天气]()

# 外部链接

- [Hacker News 讨论](https://news.ycombinator.com/item?id=6445270)

<!-- For the update:
0. fix the 0-link anomalous emails early in the sample
1. use a MLM, using a Poisson family - matches the underlying process more accurately
2. add additional level of nesting for unique subject lines but about the same subject (so it would go email-subject-lines nested under general-topics eg. all the Gene Wolfe searches should be clustered)
2. add Google Scholar & Pubmed alerts
3. add a nesting level for Google (Alerts & Scholar), and nesting for all alerts (Google & Pubmed) -->
